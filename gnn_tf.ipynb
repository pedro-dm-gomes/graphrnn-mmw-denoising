{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph NN for MMWave Sensor filtering\n",
    "The idea is to train a classifier to distinguish between fake points and actual ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 09:49:19.016944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:49:19.017005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Requirements:\n",
    "     * TF:      2.7.0\n",
    "     * Keras:   2.7.0\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "'''\n",
    "    Setting Up matplotlib for paper compliant figures\n",
    "    (this should avoid problems when compiling latex stuff)\n",
    "'''\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Where datasets are stored\n",
    "run_path = \"data/\"\n",
    "experiments_path = \"experiments/\"\n",
    "\n",
    "def load_datasets(init_path):\n",
    "    '''\n",
    "        Return dataset as list of pointclouds\n",
    "        ---\n",
    "        Parameters:\n",
    "        * init_path: string; path to folder holding folders of datasets\n",
    "                     (expected folder structure: 'init_path/run_X/labelled_mmw_run_X.json')\n",
    "    '''\n",
    "    data = []\n",
    "    for run in sorted(os.listdir(init_path)):\n",
    "        if \"run_\" in run:\n",
    "            data.extend(json.load(open(init_path+run+\"/labelled_mmw_\"+run+\".json\"))['labelled_mmw'])\n",
    "    return data\n",
    "\n",
    "def load_train_test_data(init_path, train_filter=[], test_filter=[]):\n",
    "    '''\n",
    "        Return dataset as list of pointclouds\n",
    "        ---\n",
    "        Parameters:\n",
    "        * init_path: string; path to folder holding folders of datasets\n",
    "                     (expected folder structure: 'init_path/run_X/labelled_mmw_run_X.json')\n",
    "    '''\n",
    "    train = []\n",
    "    test = []\n",
    "    for run in sorted(os.listdir(init_path)):\n",
    "        if \"run_\" in run:\n",
    "            if (int(run.split('_')[-1]) in train_filter):\n",
    "                # train.extend(json.load(open(init_path+run+\"/labelled_mmw_\"+run+\".json\"))['labelled_mmw'])\n",
    "                train.extend(json.load(open(init_path+run+\"/norm_mmw_\"+run+\".json\"))['labelled_mmw'])\n",
    "            elif (int(run.split('_')[-1]) in test_filter):\n",
    "                test.extend(json.load(open(init_path+run+\"/labelled_mmw_\"+run+\".json\"))['labelled_mmw'])\n",
    "    return train, test\n",
    "\n",
    "def get_data_and_label(data, points_per_cloud=200):\n",
    "    '''\n",
    "        Return samples for training as np.array, divided as unlabelled data and related labels.\n",
    "        ---\n",
    "        Parameters:\n",
    "        * data: list of point clouds. (Usually loaded with function load_datasets)\n",
    "        * points_per_cloud: number of points to be found in each point cloud. (Default is 200)\n",
    "    '''\n",
    "    d_x, d_y = [], []\n",
    "    for pc in data:\n",
    "        for i in range(0, len(pc), points_per_cloud): \n",
    "            if len(pc[i:i+points_per_cloud]) == points_per_cloud:\n",
    "                t_ = np.array(pc[i:i+points_per_cloud])[:, :3]\n",
    "                d_x.append(t_)\n",
    "                d_y.append(np.array(pc[i:i+points_per_cloud], dtype=np.float32)[:, -1])\n",
    "                # d_y.append(tf.one_hot(np.array(pc[i:i+points_per_cloud], dtype=np.float32)[:, -1], 2)) # One Hotted\n",
    "    d_x, d_y = np.stack(d_x), np.stack(d_y)\n",
    "    return d_x, d_y\n",
    "\n",
    "train_filter=[4,6,8,9,50,51,53,54,56,58,59,61,62,63,65,66,67,69]\n",
    "test_filter=[3,7,49,55,57,64,68,70]\n",
    "\n",
    "# dataset = load_datasets(run_path)\n",
    "train, test = load_train_test_data(run_path, train_filter=train_filter, test_filter=test_filter)\n",
    "\n",
    "# Separate Train and Test data\n",
    "# d_len = int(len(dataset)*0.7)\n",
    "# train, test = dataset[:d_len], dataset[d_len:]\n",
    "\n",
    "\n",
    "# Shuffle point cloud dataset\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)\n",
    "\n",
    "# Get X and Y data for training\n",
    "train_x, train_y = get_data_and_label(train)\n",
    "test_x, test_y = get_data_and_label(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Graph CNN \n",
    "#### https://github.com/WangYueFt/dgcnn\n",
    "#### https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_conv2d(inputs,\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            stride=[1],\n",
    "            padding='SAME',\n",
    "            use_xavier=True,\n",
    "            stddev=1e-3,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            bn=False):\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        strides=stride, \n",
    "        padding=padding,\n",
    "        activation=activation_fn,\n",
    "        kernel_initializer='glorot_uniform' if use_xavier else keras.initializers.TruncatedNormal(stddev=stddev),\n",
    "        bias_initializer='zeros'\n",
    "    )(inputs)\n",
    "\n",
    "    if bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    return x\n",
    "\n",
    "def gnn_dense(inputs,\n",
    "            units,\n",
    "            use_xavier=True,\n",
    "            stddev=1e-3,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            bn=False):\n",
    "            \n",
    "    x = layers.Dense(units,\n",
    "        activation=activation_fn,\n",
    "        kernel_initializer='glorot_uniform' if use_xavier else keras.initializers.TruncatedNormal(stddev=stddev),\n",
    "        bias_initializer='zeros'\n",
    "    )(inputs)\n",
    "\n",
    "    if bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    return x\n",
    "\n",
    "def lambda_get_adj_matr(input):\n",
    "    pcT = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1]))(input)\n",
    "    pc_inn = layers.Lambda(lambda x: tf.matmul(x[0], x[1]))( (input, pcT) )\n",
    "    pc2 = layers.Lambda(lambda x: tf.reduce_sum(tf.square(x), axis=-1, keepdims=True))(input)\n",
    "    pc2T = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1]))(pc2)\n",
    "    output = layers.Lambda(lambda x: x[0] + -2 * x[1] + x[2])( (pc2, pc_inn, pc2T) )\n",
    "    # Uncomment line below to use reciprocal of adj matrix (1/distance)\n",
    "    # output = layers.Lambda(lambda x: tf.math.reciprocal(x))(output)\n",
    "    return output\n",
    "\n",
    "def lambda_knn(adj, k=20):\n",
    "    x = layers.Lambda(lambda x: tf.math.top_k(-x[0], x[1]))( (adj, k) )\n",
    "    return x.indices\n",
    "\n",
    "def lambda_edge_feature(inputs, nn_idxs, k=20, num_points=200, num_dims=3):\n",
    "\n",
    "    pc_central = inputs\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "    idx_ = layers.Lambda(lambda x: tf.range(x[0]) * x[1])( (batch_size, num_points) )\n",
    "    idx_ = layers.Lambda(lambda x: tf.reshape(x[0], (x[1], 1, 1)))( (idx_, batch_size) )\n",
    "    # Adding to list of idxs of k points the points themselves\n",
    "    pc_temp1 = layers.Lambda(lambda x: x[0]+x[1])( (nn_idxs, idx_) )\n",
    "\n",
    "    # Flattening of points into a list of coordinates (x,y,z)\n",
    "    pc_flat = layers.Lambda(lambda x: tf.reshape(x[0], [-1, x[1]]))( (inputs, num_dims) )\n",
    "\n",
    "    # Collect points from computed idxs\n",
    "    pc_neighbors = layers.Lambda(lambda x: tf.gather(x[0], x[1]) )( (pc_flat, pc_temp1) )\n",
    "\n",
    "    # Reshape points into shape (batch, num_points, NEW_AXIS = 1, num_dims)\n",
    "    pc_central = layers.Lambda(lambda x: tf.expand_dims(x, axis=-2))(pc_central)\n",
    "    # Points are repeated k-times along new dimension ==> (batch, num_points, k, num_dims)\n",
    "    pc_central = layers.Lambda(lambda x: tf.tile(x[0], [1, 1, x[1], 1]))( (pc_central, k) )\n",
    "\n",
    "    pc_temp2 = layers.Lambda(lambda x: tf.subtract(x[0], x[1]))( (pc_neighbors, pc_central) )\n",
    "    edge_feature = layers.Lambda(lambda x: tf.concat((x[0], x[1]), axis=-1))((pc_central, pc_temp2))\n",
    "    return edge_feature\n",
    "\n",
    "class CustomOrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features=3, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'num_features': self.num_features, 'l2reg': self.l2reg}\n",
    "\n",
    "def gnn_tnet(inputs, num_dims, tnet_shapes, bn=False):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    for filt in tnet_shapes[0]:\n",
    "        x = gnn_conv2d(inputs, filters=filt, kernel_size=[1], bn=bn)\n",
    "    # x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "    for filt in tnet_shapes[1]:\n",
    "        x = gnn_conv2d(inputs, filters=filt, kernel_size=[1], bn=bn)\n",
    "    x = layers.GlobalMaxPooling1D(keepdims=True)(x)\n",
    "    # print(\" [tnet] global maxpool 2d shape: \", x.shape)\n",
    "    x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], y[2])))( [x, batch_size, x.shape[-1]] )\n",
    "    # print(\" [tnet] reshape: \", x.shape)\n",
    "\n",
    "    for neur in tnet_shapes[2]:\n",
    "        x = gnn_dense(x, neur, bn)\n",
    "    \n",
    "    bias = keras.initializers.Constant(np.eye(num_dims).flatten())\n",
    "    reg = CustomOrthogonalRegularizer(num_features=num_dims)\n",
    "    x = layers.Dense(\n",
    "        num_dims * num_dims,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_dims, num_dims), name='tnet_last_reshape'+str(np.round(time.time(), 5)))(x)\n",
    "    return feat_T\n",
    "\n",
    "# function to test custom losses\n",
    "def custom_loss(pred, labels):\n",
    "    # loss = tf.compat.v1.losses.softmax_cross_entropy(onehot_labels=labels, logits=pred, label_smoothing=0.2)\n",
    "    # classify_loss = tf.reduce_mean(loss)\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.math.square(tf.math.subtract(labels, pred)), axis=-1))\n",
    "    return loss\n",
    "\n",
    "'''\n",
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "tf.math.l2_normalize\n",
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "'''\n",
    "\n",
    "# Callback to save good models. Threshold is on validation accuracy.\n",
    "class ValAccThresh_CB(keras.callbacks.Callback):\n",
    "    def __init__(self, thresh=0.85, experiments_path=\"experiments/\", test_name=\"test\"):\n",
    "        self.thresh = thresh\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "        self.stopped_epoch = 0\n",
    "        self.experiments_path = experiments_path\n",
    "        self.test_name = test_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # self.current_epoch += 1\n",
    "        val_key = \"\"\n",
    "        for k in logs.keys():\n",
    "            if \"val\" in k and \"accuracy\" in k:\n",
    "                val_key = k\n",
    "                break\n",
    "        assert logs.get(val_key) != None, print(\" Validation Accuracy not found\", self.thresh, logs.get(val_key), val_key, logs.get(val_key) == None)\n",
    "\n",
    "        current = logs.get(val_key)\n",
    "        # current = logs.get(\"val_sparse_categorical_accuracy\")\n",
    "        # current = logs.get(\"val_accuracy\")\n",
    "        if current >= self.thresh:\n",
    "            self.thresh = current\n",
    "            self.model.save_weights(self.experiments_path+self.test_name+\"/best_weights/cp-\"+str(epoch)+\".ckpt\")\n",
    "            print(\" New good model saved.\")\n",
    "\n",
    "# Callback to save history for post-processing\n",
    "# filename=experiments_path+test_name+\"/history.csv\"\n",
    "# history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "# test_name = \"test_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, \n",
    "        num_points, num_dims, k,\n",
    "        tnet_shape,\n",
    "        conv_gnns,\n",
    "        dense_gnn,\n",
    "        classes=2):\n",
    "    '''\n",
    "        Returns the outputs of the model to be compiled.\n",
    "        ---\n",
    "        Arguments: \n",
    "        * inputs:       Expected (None, 3). instance of tf.Input.\n",
    "        * num_points:   Number of points per point cloud. Default is 200\n",
    "        * num_dims:     Number of dimensions per point. Default is 3 (x, y, z)\n",
    "        * k:            K nearest neighbors\n",
    "        * tnet_shape:   Array of three lists. (each list's length is the number of layers for that section)\n",
    "                        1st is a list of filters for convolutional layers before reduce_max.\n",
    "                        2nd is a list of filters for convolutional layers after reduce_max.\n",
    "                        3rd is a list of neurons for dense layers after max pooling.\n",
    "        * conv_gnns:    list. Each row is composed of two lists.\n",
    "                        1st is a list of filters for convolutional layers before computing edge features.\n",
    "                        2nd is a list of filters for convolutional layers after computing edge features.\n",
    "        * dense_gnn:    list of neuorns for dense layers at the end of the network.\n",
    "        * classes:      number of classes to classify.\n",
    "    '''\n",
    "\n",
    "    # adj = lambda_get_adj_matr(inputs)\n",
    "    # nn_idxs = lambda_knn(adj, k)\n",
    "    # edge_feats = lambda_edge_feature(inputs, nn_idxs, k, num_points, num_dims)\n",
    "    feat_T = gnn_tnet(inputs, num_dims, tnet_shape[0], bn=True)\n",
    "    # print(\" [main] tnet shape: \", inputs.shape, feat_T.shape)\n",
    "    pc_tf = layers.Dot(axes=(-1, -2))([inputs, feat_T]) # Apply affine transformation to input features\n",
    "    # print(\" [main] dot shape: \", pc_tf.shape)\n",
    "\n",
    "    # adj = lambda_get_adj_matr(pc_tf)\n",
    "    # nn_idxs = lambda_knn(adj, k)\n",
    "    # edge_feats = lambda_edge_feature(pc_tf, nn_idxs, k, num_points, num_dims)\n",
    "    # x = edge_feats\n",
    "    x = pc_tf\n",
    "\n",
    "    for l in conv_gnns:\n",
    "\n",
    "        for gc_filt in l[0]:\n",
    "            x = gnn_conv2d(x, gc_filt, [1], bn=True)\n",
    "        \n",
    "        # x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "        # x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], num_points, l[0][-1])))( [x, tf.shape(inputs)[0]] )\n",
    "\n",
    "        # adj = lambda_get_adj_matr(x)\n",
    "        # nn_idxs = lambda_knn(adj, k)\n",
    "        # edge_feats = lambda_edge_feature(x, nn_idxs, k, num_points, l[0][-1])\n",
    "        # x = edge_feats\n",
    "\n",
    "        feat_T = gnn_tnet(x, x.shape[-1], tnet_shape[1], bn=True)\n",
    "        # print(\" [main] tnet SHAPES: \", x.shape, feat_T.shape)\n",
    "        x = layers.Dot(axes=(-1, -2))([x, feat_T])\n",
    "        # print(\" [main] DOT SHAPE: \", x.shape)\n",
    "\n",
    "        # adj = lambda_get_adj_matr(x)\n",
    "        # nn_idxs = lambda_knn(adj, k)\n",
    "        # edge_feats = lambda_edge_feature(x, nn_idxs, k, num_points, x.shape[-1])\n",
    "\n",
    "        for gc_filt in l[1]:\n",
    "            x = gnn_conv2d(x, gc_filt, [1], bn=True)\n",
    "        # x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "        # x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], num_points, l[1][-1])))( [x, tf.shape(inputs)[0]] )\n",
    "\n",
    "    # x = layers.GlobalMaxPooling1D(keepdims=True)(x)\n",
    "    # x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], y[2])))( [x, tf.shape(x)[0], x.shape[-1]] )\n",
    "    \n",
    "    for w_ in dense_gnn:\n",
    "        x = gnn_dense(x, w_, bn=True)\n",
    "\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    return outputs\n",
    "\n",
    "def objective(trial):\n",
    "    test_name = \"fixed_test_\"+str(trial.number)\n",
    "    filename=experiments_path+test_name+\"/history.csv\"\n",
    "    history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "    ############################ HyperParameter Setup ############################\n",
    "    ######################### Check build_model for docs #########################\n",
    "    k = trial.suggest_int('k', 5,75) #30\n",
    "    batch_size = trial.suggest_int('batch_size', 8,128) #16\n",
    "    # tnet_before_max = trial.suggest_int('tnet_before_max', 1,3)\n",
    "    # tnet_before = []\n",
    "    # for i in range(tnet_before_max):\n",
    "    #     tnet_before.append(trial.suggest_int('tnet_beforemax_layer_'+str(i), 8,128))\n",
    "    # tnet_after = []\n",
    "    # tnet_after_max = trial.suggest_int('tnet_after_max', 1,3)\n",
    "    # for i in range(tnet_after_max):\n",
    "    #     tnet_after.append(trial.suggest_int('tnet_aftermax_layer_'+str(i), 8,128))\n",
    "    # tnet_dense = []\n",
    "    # tnet_dense_layers = trial.suggest_int('tnet_dense_layers', 1,3)\n",
    "    # for i in range(tnet_dense_layers):\n",
    "    #     tnet_dense.append(trial.suggest_int('tnet_dense_layer_'+str(i), 16,256))\n",
    "    tnet_before = [32]\n",
    "    tnet_after = [128]\n",
    "    tnet_dense = [128, 128]\n",
    "    tnet_shape = [tnet_before, tnet_after, tnet_dense]\n",
    "\n",
    "    # gc_layers = trial.suggest_int('gc_layers', 1,3) #1\n",
    "    conv_gnns = []\n",
    "    # for _ in range(gc_layers):\n",
    "    #     before_edge_gcl = trial.suggest_int('before_edge_gcl', 1,3) #2\n",
    "    #     after_edge_gcl = trial.suggest_int('after_edge_gcl', 1,3) #2\n",
    "\n",
    "    #     bfr_edge = []\n",
    "    #     for i in range(before_edge_gcl):\n",
    "    #         bfr_edge.append(trial.suggest_int('before_edge_gcl_'+str(i), 8,128))\n",
    "            \n",
    "    #     aft_edge = []\n",
    "    #     for i in range(after_edge_gcl):\n",
    "    #         aft_edge.append(trial.suggest_int('after_edge_gcl_'+str(i), 8,128))\n",
    "            \n",
    "    #     conv_gnns.append([bfr_edge, aft_edge])\n",
    "    bfr_edge = [32, 64]\n",
    "    aft_edge = [128]\n",
    "    conv_gnns.append([bfr_edge, aft_edge])\n",
    "    # dense_layers = trial.suggest_int('dense_layers', 1,3)\n",
    "    # dense_gnn = []\n",
    "    # for i in range(dense_layers):\n",
    "    #     dense_gnn.append(trial.suggest_int('dense_layer_'+str(i), 16,256))\n",
    "    dense_gnn = [256, 128]\n",
    "        \n",
    "    lr = trial.suggest_float('lr', 0.0001, 0.1)\n",
    "    steps_per_epoch=trial.suggest_int('steps_per_epoch', 15,100)\n",
    "\n",
    "    validation_steps=25     # Static\n",
    "    num_points = 200        # Static\n",
    "    num_dims = 3            # Static\n",
    "    ##############################################################################\n",
    "\n",
    "    inputs = keras.Input(shape=(None, num_dims))\n",
    "    \n",
    "    outputs = build_model(inputs,\n",
    "                    num_points, num_dims, k,\n",
    "                    tnet_shape,\n",
    "                    conv_gnns,\n",
    "                    dense_gnn\n",
    "                )\n",
    "    model = keras.Model(inputs=[inputs], outputs=outputs, name=\"gnn_pointnet\")\n",
    "\n",
    "    opt_pi = tf.optimizers.Adam(learning_rate =  lr )\n",
    "    # opt_pi = tf.optimizers.RMSprop(learning_rate =  lr )\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_pi, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    # model.compile(loss=tf.nn.sparse_softmax_cross_entropy_with_logits , optimizer=opt_pi, metrics=['accuracy'])\n",
    "    # model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=opt_pi, metrics=['accuracy'])\n",
    "    # model.compile(loss=custom_loss, optimizer=opt_pi, metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_path = experiments_path+test_name+\"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=0, \n",
    "        save_weights_only=False,\n",
    "        save_freq=10*batch_size)\n",
    "        \n",
    "    latest = tf.train.latest_checkpoint(experiments_path+test_name+\"/\")\n",
    "    if latest:\n",
    "        model.load_weights(latest)\n",
    "        latest_ep = int(latest.split('/')[-1].split('-')[-1].split('.')[0])\n",
    "        print(\" Model loaded correctly:\", latest, \" - Epoch \", latest_ep)\n",
    "    else:\n",
    "        print(\" The model could not be loaded properly: \", latest)\n",
    "        model.save(checkpoint_path.format(epoch=0))\n",
    "        latest_ep = 0\n",
    "\n",
    "    # Use CPU as default due to GPU's memory issues\n",
    "    with tf.device('/CPU:0'):\n",
    "        history = model.fit(\n",
    "            train_x, \n",
    "            train_y, \n",
    "            \n",
    "            initial_epoch=latest_ep,\n",
    "            batch_size=batch_size, \n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "\n",
    "            validation_split=0.3,\n",
    "            epochs=150 - latest_ep, # Train for 150 epochs to find the configuration that can later be trained for more epochs.\n",
    "            shuffle=True,\n",
    "            callbacks=[ValAccThresh_CB(thresh=0.9), cp_callback, history_logger],\n",
    "            use_multiprocessing=False,\n",
    "            workers=8,\n",
    "        )\n",
    "    return np.mean(history.history['val_sparse_categorical_accuracy'][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually train\n",
    "storage = optuna.storages.RDBStorage(url=\"sqlite:///gnn_fixed.db\", engine_kwargs={\"connect_args\": {\"timeout\": 5}})\n",
    "study = optuna.create_study(study_name=\"gnn_denoising_fixed\", storage=storage, load_if_exists=True, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Configurations Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 09:51:05.890289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-20 09:51:05.891080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.891329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.891576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.891803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.892031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.892262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.892502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.892734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-03-20 09:51:05.892760: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-20 09:51:05.893284: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The model at  experiments/manual_test_double_tnet_05/ could not be loaded properly:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 09:51:10.314358: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0000.ckpt/assets\n",
      "Epoch 1/5000\n",
      "32/32 [==============================] - 29s 773ms/step - loss: 6.7756 - sparse_categorical_accuracy: 0.5120 - val_loss: 8.5638 - val_sparse_categorical_accuracy: 0.5195\n",
      "Epoch 2/5000\n",
      "32/32 [==============================] - 27s 842ms/step - loss: 5.3694 - sparse_categorical_accuracy: 0.5224 - val_loss: 8.6115 - val_sparse_categorical_accuracy: 0.5428\n",
      "Epoch 3/5000\n",
      "32/32 [==============================] - 26s 802ms/step - loss: 5.2372 - sparse_categorical_accuracy: 0.5227 - val_loss: 8.4478 - val_sparse_categorical_accuracy: 0.5597\n",
      "Epoch 4/5000\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 5.1957 - sparse_categorical_accuracy: 0.5287 - val_loss: 8.2124 - val_sparse_categorical_accuracy: 0.5725\n",
      "Epoch 5/5000\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 5.1674 - sparse_categorical_accuracy: 0.5286 - val_loss: 7.8921 - val_sparse_categorical_accuracy: 0.5628\n",
      "Epoch 6/5000\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 5.0945 - sparse_categorical_accuracy: 0.5325 - val_loss: 7.4750 - val_sparse_categorical_accuracy: 0.5752\n",
      "Epoch 7/5000\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 5.1009 - sparse_categorical_accuracy: 0.5314 - val_loss: 7.0754 - val_sparse_categorical_accuracy: 0.5801\n",
      "Epoch 8/5000\n",
      "32/32 [==============================] - 27s 846ms/step - loss: 5.0715 - sparse_categorical_accuracy: 0.5346 - val_loss: 6.6923 - val_sparse_categorical_accuracy: 0.5823\n",
      "Epoch 9/5000\n",
      "32/32 [==============================] - 25s 780ms/step - loss: 5.0233 - sparse_categorical_accuracy: 0.5364 - val_loss: 6.3232 - val_sparse_categorical_accuracy: 0.5508\n",
      "Epoch 10/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 5.0337 - sparse_categorical_accuracy: 0.5417INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0010.ckpt/assets\n",
      "32/32 [==============================] - 35s 1s/step - loss: 5.0339 - sparse_categorical_accuracy: 0.5416 - val_loss: 6.0071 - val_sparse_categorical_accuracy: 0.5850\n",
      "Epoch 11/5000\n",
      "32/32 [==============================] - 26s 829ms/step - loss: 4.9938 - sparse_categorical_accuracy: 0.5398 - val_loss: 5.7307 - val_sparse_categorical_accuracy: 0.5716\n",
      "Epoch 12/5000\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 4.9991 - sparse_categorical_accuracy: 0.5436 - val_loss: 5.5562 - val_sparse_categorical_accuracy: 0.5719\n",
      "Epoch 13/5000\n",
      "32/32 [==============================] - 24s 753ms/step - loss: 4.9923 - sparse_categorical_accuracy: 0.5434 - val_loss: 5.3733 - val_sparse_categorical_accuracy: 0.5928\n",
      "Epoch 14/5000\n",
      "32/32 [==============================] - 29s 923ms/step - loss: 4.9507 - sparse_categorical_accuracy: 0.5462 - val_loss: 5.2735 - val_sparse_categorical_accuracy: 0.5893\n",
      "Epoch 15/5000\n",
      "32/32 [==============================] - 25s 794ms/step - loss: 4.9667 - sparse_categorical_accuracy: 0.5499 - val_loss: 5.2296 - val_sparse_categorical_accuracy: 0.6091\n",
      "Epoch 16/5000\n",
      "32/32 [==============================] - 23s 712ms/step - loss: 4.9693 - sparse_categorical_accuracy: 0.5456 - val_loss: 5.1470 - val_sparse_categorical_accuracy: 0.6104\n",
      "Epoch 17/5000\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 4.9207 - sparse_categorical_accuracy: 0.5485 - val_loss: 5.1060 - val_sparse_categorical_accuracy: 0.6069\n",
      "Epoch 18/5000\n",
      "32/32 [==============================] - 22s 703ms/step - loss: 4.9546 - sparse_categorical_accuracy: 0.5453 - val_loss: 5.0434 - val_sparse_categorical_accuracy: 0.6221\n",
      "Epoch 19/5000\n",
      "32/32 [==============================] - 22s 695ms/step - loss: 4.9331 - sparse_categorical_accuracy: 0.5521 - val_loss: 5.0284 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 20/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8960 - sparse_categorical_accuracy: 0.5569INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0020.ckpt/assets\n",
      "32/32 [==============================] - 31s 984ms/step - loss: 4.8955 - sparse_categorical_accuracy: 0.5571 - val_loss: 4.9823 - val_sparse_categorical_accuracy: 0.6156\n",
      "Epoch 21/5000\n",
      "32/32 [==============================] - 22s 700ms/step - loss: 4.9231 - sparse_categorical_accuracy: 0.5522 - val_loss: 4.9924 - val_sparse_categorical_accuracy: 0.5860\n",
      "Epoch 22/5000\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 4.8897 - sparse_categorical_accuracy: 0.5576 - val_loss: 4.9749 - val_sparse_categorical_accuracy: 0.5800\n",
      "Epoch 23/5000\n",
      "32/32 [==============================] - 22s 701ms/step - loss: 4.9045 - sparse_categorical_accuracy: 0.5577 - val_loss: 4.9446 - val_sparse_categorical_accuracy: 0.6168\n",
      "Epoch 24/5000\n",
      "32/32 [==============================] - 23s 710ms/step - loss: 4.9082 - sparse_categorical_accuracy: 0.5548 - val_loss: 4.9331 - val_sparse_categorical_accuracy: 0.6013\n",
      "Epoch 25/5000\n",
      "32/32 [==============================] - 22s 684ms/step - loss: 4.8724 - sparse_categorical_accuracy: 0.5592 - val_loss: 4.9060 - val_sparse_categorical_accuracy: 0.6120\n",
      "Epoch 26/5000\n",
      "32/32 [==============================] - 23s 708ms/step - loss: 4.8960 - sparse_categorical_accuracy: 0.5578 - val_loss: 4.9188 - val_sparse_categorical_accuracy: 0.6204\n",
      "Epoch 27/5000\n",
      "32/32 [==============================] - 22s 702ms/step - loss: 4.8888 - sparse_categorical_accuracy: 0.5596 - val_loss: 4.9239 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 28/5000\n",
      "32/32 [==============================] - 22s 687ms/step - loss: 4.8578 - sparse_categorical_accuracy: 0.5661 - val_loss: 4.9273 - val_sparse_categorical_accuracy: 0.6184\n",
      "Epoch 29/5000\n",
      "32/32 [==============================] - 22s 705ms/step - loss: 4.8868 - sparse_categorical_accuracy: 0.5631 - val_loss: 4.9004 - val_sparse_categorical_accuracy: 0.6085\n",
      "Epoch 30/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8566 - sparse_categorical_accuracy: 0.5611INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0030.ckpt/assets\n",
      "32/32 [==============================] - 29s 919ms/step - loss: 4.8574 - sparse_categorical_accuracy: 0.5611 - val_loss: 4.8988 - val_sparse_categorical_accuracy: 0.6063\n",
      "Epoch 31/5000\n",
      "32/32 [==============================] - 26s 836ms/step - loss: 4.8756 - sparse_categorical_accuracy: 0.5654 - val_loss: 4.8874 - val_sparse_categorical_accuracy: 0.6191\n",
      "Epoch 32/5000\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 4.8719 - sparse_categorical_accuracy: 0.5668 - val_loss: 4.8996 - val_sparse_categorical_accuracy: 0.6060\n",
      "Epoch 33/5000\n",
      "32/32 [==============================] - 26s 801ms/step - loss: 4.8360 - sparse_categorical_accuracy: 0.5643 - val_loss: 4.9104 - val_sparse_categorical_accuracy: 0.6183\n",
      "Epoch 34/5000\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 4.8712 - sparse_categorical_accuracy: 0.5624 - val_loss: 4.9009 - val_sparse_categorical_accuracy: 0.6148\n",
      "Epoch 35/5000\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 4.8534 - sparse_categorical_accuracy: 0.5667 - val_loss: 4.8967 - val_sparse_categorical_accuracy: 0.6105\n",
      "Epoch 36/5000\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 4.8262 - sparse_categorical_accuracy: 0.5741 - val_loss: 4.9204 - val_sparse_categorical_accuracy: 0.5860\n",
      "Epoch 37/5000\n",
      "32/32 [==============================] - 26s 829ms/step - loss: 4.8538 - sparse_categorical_accuracy: 0.5680 - val_loss: 4.9059 - val_sparse_categorical_accuracy: 0.6109\n",
      "Epoch 38/5000\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 4.8542 - sparse_categorical_accuracy: 0.5615 - val_loss: 4.8838 - val_sparse_categorical_accuracy: 0.6083\n",
      "Epoch 39/5000\n",
      "32/32 [==============================] - 25s 796ms/step - loss: 4.8196 - sparse_categorical_accuracy: 0.5681 - val_loss: 4.9275 - val_sparse_categorical_accuracy: 0.6099\n",
      "Epoch 40/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8422 - sparse_categorical_accuracy: 0.5729INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0040.ckpt/assets\n",
      "32/32 [==============================] - 36s 1s/step - loss: 4.8422 - sparse_categorical_accuracy: 0.5730 - val_loss: 4.8905 - val_sparse_categorical_accuracy: 0.6078\n",
      "Epoch 41/5000\n",
      "32/32 [==============================] - 26s 804ms/step - loss: 4.8202 - sparse_categorical_accuracy: 0.5682 - val_loss: 4.9504 - val_sparse_categorical_accuracy: 0.6177\n",
      "Epoch 42/5000\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 4.8461 - sparse_categorical_accuracy: 0.5670 - val_loss: 4.8947 - val_sparse_categorical_accuracy: 0.6012\n",
      "Epoch 43/5000\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 4.8257 - sparse_categorical_accuracy: 0.5795 - val_loss: 4.8821 - val_sparse_categorical_accuracy: 0.6158\n",
      "Epoch 44/5000\n",
      "32/32 [==============================] - 26s 804ms/step - loss: 4.8162 - sparse_categorical_accuracy: 0.5664 - val_loss: 4.8880 - val_sparse_categorical_accuracy: 0.6053\n",
      "Epoch 45/5000\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 4.8349 - sparse_categorical_accuracy: 0.5728 - val_loss: 4.9225 - val_sparse_categorical_accuracy: 0.5963\n",
      "Epoch 46/5000\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 4.8216 - sparse_categorical_accuracy: 0.5828 - val_loss: 4.8826 - val_sparse_categorical_accuracy: 0.6137\n",
      "Epoch 47/5000\n",
      "32/32 [==============================] - 26s 801ms/step - loss: 4.8044 - sparse_categorical_accuracy: 0.5793 - val_loss: 4.8952 - val_sparse_categorical_accuracy: 0.6219\n",
      "Epoch 48/5000\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 4.8148 - sparse_categorical_accuracy: 0.5859 - val_loss: 4.9113 - val_sparse_categorical_accuracy: 0.5994\n",
      "Epoch 49/5000\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 4.7952 - sparse_categorical_accuracy: 0.5870 - val_loss: 4.8971 - val_sparse_categorical_accuracy: 0.6121\n",
      "Epoch 50/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.8180 - sparse_categorical_accuracy: 0.5829INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0050.ckpt/assets\n",
      "32/32 [==============================] - 35s 1s/step - loss: 4.8165 - sparse_categorical_accuracy: 0.5839 - val_loss: 4.8882 - val_sparse_categorical_accuracy: 0.5963\n",
      "Epoch 51/5000\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 4.8295 - sparse_categorical_accuracy: 0.5748 - val_loss: 4.9255 - val_sparse_categorical_accuracy: 0.6173\n",
      "Epoch 52/5000\n",
      "32/32 [==============================] - 26s 803ms/step - loss: 4.7944 - sparse_categorical_accuracy: 0.5857 - val_loss: 4.9328 - val_sparse_categorical_accuracy: 0.6089\n",
      "Epoch 53/5000\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 4.8152 - sparse_categorical_accuracy: 0.5850 - val_loss: 4.9219 - val_sparse_categorical_accuracy: 0.6025\n",
      "Epoch 54/5000\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 4.8207 - sparse_categorical_accuracy: 0.5767 - val_loss: 4.8976 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 55/5000\n",
      "32/32 [==============================] - 23s 707ms/step - loss: 4.7866 - sparse_categorical_accuracy: 0.5839 - val_loss: 4.9182 - val_sparse_categorical_accuracy: 0.6267\n",
      "Epoch 56/5000\n",
      "32/32 [==============================] - 24s 742ms/step - loss: 4.8135 - sparse_categorical_accuracy: 0.5857 - val_loss: 4.8965 - val_sparse_categorical_accuracy: 0.6123\n",
      "Epoch 57/5000\n",
      "32/32 [==============================] - 23s 724ms/step - loss: 4.8074 - sparse_categorical_accuracy: 0.5908 - val_loss: 4.8946 - val_sparse_categorical_accuracy: 0.6331\n",
      "Epoch 58/5000\n",
      "32/32 [==============================] - 23s 709ms/step - loss: 4.7845 - sparse_categorical_accuracy: 0.5889 - val_loss: 4.8981 - val_sparse_categorical_accuracy: 0.6269\n",
      "Epoch 59/5000\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 4.8021 - sparse_categorical_accuracy: 0.5936 - val_loss: 4.9188 - val_sparse_categorical_accuracy: 0.6081\n",
      "Epoch 60/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7802 - sparse_categorical_accuracy: 0.5954INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0060.ckpt/assets\n",
      "32/32 [==============================] - 39s 1s/step - loss: 4.7803 - sparse_categorical_accuracy: 0.5959 - val_loss: 4.8794 - val_sparse_categorical_accuracy: 0.6263\n",
      "Epoch 61/5000\n",
      "32/32 [==============================] - 29s 912ms/step - loss: 4.8159 - sparse_categorical_accuracy: 0.5892 - val_loss: 4.8548 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 62/5000\n",
      "32/32 [==============================] - 24s 746ms/step - loss: 4.7970 - sparse_categorical_accuracy: 0.5946 - val_loss: 4.8796 - val_sparse_categorical_accuracy: 0.6306\n",
      "Epoch 63/5000\n",
      "32/32 [==============================] - 24s 746ms/step - loss: 4.7776 - sparse_categorical_accuracy: 0.5953 - val_loss: 4.8913 - val_sparse_categorical_accuracy: 0.6182\n",
      "Epoch 64/5000\n",
      "32/32 [==============================] - 25s 794ms/step - loss: 4.8197 - sparse_categorical_accuracy: 0.5861 - val_loss: 4.9248 - val_sparse_categorical_accuracy: 0.6162\n",
      "Epoch 65/5000\n",
      "32/32 [==============================] - 25s 774ms/step - loss: 4.7995 - sparse_categorical_accuracy: 0.5965 - val_loss: 4.8891 - val_sparse_categorical_accuracy: 0.6140\n",
      "Epoch 66/5000\n",
      "32/32 [==============================] - 22s 681ms/step - loss: 4.7706 - sparse_categorical_accuracy: 0.5996 - val_loss: 4.8858 - val_sparse_categorical_accuracy: 0.6108\n",
      "Epoch 67/5000\n",
      "32/32 [==============================] - 23s 723ms/step - loss: 4.7926 - sparse_categorical_accuracy: 0.6024 - val_loss: 4.8895 - val_sparse_categorical_accuracy: 0.6337\n",
      "Epoch 68/5000\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 4.7701 - sparse_categorical_accuracy: 0.5987 - val_loss: 4.8909 - val_sparse_categorical_accuracy: 0.6283\n",
      "Epoch 69/5000\n",
      "32/32 [==============================] - 22s 695ms/step - loss: 4.7918 - sparse_categorical_accuracy: 0.6054 - val_loss: 4.8935 - val_sparse_categorical_accuracy: 0.6203\n",
      "Epoch 70/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7939 - sparse_categorical_accuracy: 0.6024INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0070.ckpt/assets\n",
      "32/32 [==============================] - 31s 975ms/step - loss: 4.7943 - sparse_categorical_accuracy: 0.6024 - val_loss: 4.8736 - val_sparse_categorical_accuracy: 0.6223\n",
      "Epoch 71/5000\n",
      "32/32 [==============================] - 29s 907ms/step - loss: 4.7641 - sparse_categorical_accuracy: 0.6036 - val_loss: 4.8934 - val_sparse_categorical_accuracy: 0.6132\n",
      "Epoch 72/5000\n",
      "32/32 [==============================] - 28s 878ms/step - loss: 4.7855 - sparse_categorical_accuracy: 0.6169 - val_loss: 4.8577 - val_sparse_categorical_accuracy: 0.6198\n",
      "Epoch 73/5000\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 4.7839 - sparse_categorical_accuracy: 0.6012 - val_loss: 4.8743 - val_sparse_categorical_accuracy: 0.6152\n",
      "Epoch 74/5000\n",
      "32/32 [==============================] - 24s 755ms/step - loss: 4.7678 - sparse_categorical_accuracy: 0.5993 - val_loss: 4.8488 - val_sparse_categorical_accuracy: 0.6126\n",
      "Epoch 75/5000\n",
      "32/32 [==============================] - 24s 770ms/step - loss: 4.7953 - sparse_categorical_accuracy: 0.5997 - val_loss: 4.8439 - val_sparse_categorical_accuracy: 0.6257\n",
      "Epoch 76/5000\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 4.7809 - sparse_categorical_accuracy: 0.6147 - val_loss: 4.8505 - val_sparse_categorical_accuracy: 0.6315\n",
      "Epoch 77/5000\n",
      "32/32 [==============================] - 25s 785ms/step - loss: 4.7534 - sparse_categorical_accuracy: 0.6147 - val_loss: 4.8718 - val_sparse_categorical_accuracy: 0.6362\n",
      "Epoch 78/5000\n",
      "32/32 [==============================] - 25s 801ms/step - loss: 4.7830 - sparse_categorical_accuracy: 0.6175 - val_loss: 4.8743 - val_sparse_categorical_accuracy: 0.6204\n",
      "Epoch 79/5000\n",
      "32/32 [==============================] - 22s 707ms/step - loss: 4.7631 - sparse_categorical_accuracy: 0.6053 - val_loss: 4.8667 - val_sparse_categorical_accuracy: 0.6297\n",
      "Epoch 80/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7914 - sparse_categorical_accuracy: 0.6086INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0080.ckpt/assets\n",
      "32/32 [==============================] - 36s 1s/step - loss: 4.7917 - sparse_categorical_accuracy: 0.6084 - val_loss: 4.8638 - val_sparse_categorical_accuracy: 0.6106\n",
      "Epoch 81/5000\n",
      "32/32 [==============================] - 26s 833ms/step - loss: 4.7820 - sparse_categorical_accuracy: 0.6180 - val_loss: 4.8419 - val_sparse_categorical_accuracy: 0.6279\n",
      "Epoch 82/5000\n",
      "32/32 [==============================] - 28s 870ms/step - loss: 4.7495 - sparse_categorical_accuracy: 0.6201 - val_loss: 4.8870 - val_sparse_categorical_accuracy: 0.6289\n",
      "Epoch 83/5000\n",
      "32/32 [==============================] - 27s 837ms/step - loss: 4.7917 - sparse_categorical_accuracy: 0.6041 - val_loss: 4.8624 - val_sparse_categorical_accuracy: 0.6303\n",
      "Epoch 84/5000\n",
      "32/32 [==============================] - 27s 861ms/step - loss: 4.7818 - sparse_categorical_accuracy: 0.6079 - val_loss: 4.8698 - val_sparse_categorical_accuracy: 0.6184\n",
      "Epoch 85/5000\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 4.7599 - sparse_categorical_accuracy: 0.6084 - val_loss: 4.8389 - val_sparse_categorical_accuracy: 0.6251\n",
      "Epoch 86/5000\n",
      "32/32 [==============================] - 28s 864ms/step - loss: 4.7745 - sparse_categorical_accuracy: 0.6244 - val_loss: 4.8398 - val_sparse_categorical_accuracy: 0.6150\n",
      "Epoch 87/5000\n",
      "32/32 [==============================] - 24s 736ms/step - loss: 4.7523 - sparse_categorical_accuracy: 0.6126 - val_loss: 4.8532 - val_sparse_categorical_accuracy: 0.6360\n",
      "Epoch 88/5000\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 4.7779 - sparse_categorical_accuracy: 0.6239 - val_loss: 4.8459 - val_sparse_categorical_accuracy: 0.6201\n",
      "Epoch 89/5000\n",
      "32/32 [==============================] - 26s 800ms/step - loss: 4.7755 - sparse_categorical_accuracy: 0.6218 - val_loss: 4.8321 - val_sparse_categorical_accuracy: 0.6250\n",
      "Epoch 90/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7542 - sparse_categorical_accuracy: 0.6101INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0090.ckpt/assets\n",
      "32/32 [==============================] - 31s 967ms/step - loss: 4.7547 - sparse_categorical_accuracy: 0.6103 - val_loss: 4.8702 - val_sparse_categorical_accuracy: 0.6312\n",
      "Epoch 91/5000\n",
      "32/32 [==============================] - 16s 516ms/step - loss: 4.7822 - sparse_categorical_accuracy: 0.6190 - val_loss: 4.8646 - val_sparse_categorical_accuracy: 0.6240\n",
      "Epoch 92/5000\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 4.7690 - sparse_categorical_accuracy: 0.6264 - val_loss: 4.8403 - val_sparse_categorical_accuracy: 0.6180\n",
      "Epoch 93/5000\n",
      "32/32 [==============================] - 15s 472ms/step - loss: 4.7537 - sparse_categorical_accuracy: 0.6155 - val_loss: 4.8466 - val_sparse_categorical_accuracy: 0.6252\n",
      "Epoch 94/5000\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 4.7801 - sparse_categorical_accuracy: 0.6198 - val_loss: 4.8410 - val_sparse_categorical_accuracy: 0.6214\n",
      "Epoch 95/5000\n",
      "32/32 [==============================] - 17s 537ms/step - loss: 4.7649 - sparse_categorical_accuracy: 0.6280 - val_loss: 4.8447 - val_sparse_categorical_accuracy: 0.6212\n",
      "Epoch 96/5000\n",
      "32/32 [==============================] - 17s 519ms/step - loss: 4.7483 - sparse_categorical_accuracy: 0.6224 - val_loss: 4.8556 - val_sparse_categorical_accuracy: 0.6308\n",
      "Epoch 97/5000\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 4.7696 - sparse_categorical_accuracy: 0.6176 - val_loss: 4.8371 - val_sparse_categorical_accuracy: 0.6352\n",
      "Epoch 98/5000\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 4.7452 - sparse_categorical_accuracy: 0.6317 - val_loss: 4.8452 - val_sparse_categorical_accuracy: 0.6299\n",
      "Epoch 99/5000\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 4.7830 - sparse_categorical_accuracy: 0.6141 - val_loss: 4.8416 - val_sparse_categorical_accuracy: 0.6290\n",
      "Epoch 100/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7652 - sparse_categorical_accuracy: 0.6260INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0100.ckpt/assets\n",
      "32/32 [==============================] - 24s 773ms/step - loss: 4.7644 - sparse_categorical_accuracy: 0.6274 - val_loss: 4.8557 - val_sparse_categorical_accuracy: 0.6247\n",
      "Epoch 101/5000\n",
      "32/32 [==============================] - 17s 528ms/step - loss: 4.7526 - sparse_categorical_accuracy: 0.6151 - val_loss: 4.8729 - val_sparse_categorical_accuracy: 0.6163\n",
      "Epoch 102/5000\n",
      "32/32 [==============================] - 16s 516ms/step - loss: 4.7738 - sparse_categorical_accuracy: 0.6174 - val_loss: 4.8367 - val_sparse_categorical_accuracy: 0.6236\n",
      "Epoch 103/5000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 4.7730 - sparse_categorical_accuracy: 0.6232 - val_loss: 4.8380 - val_sparse_categorical_accuracy: 0.6305\n",
      "Epoch 104/5000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 4.7512 - sparse_categorical_accuracy: 0.6092 - val_loss: 4.8430 - val_sparse_categorical_accuracy: 0.6175\n",
      "Epoch 105/5000\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 4.7798 - sparse_categorical_accuracy: 0.6165 - val_loss: 4.8247 - val_sparse_categorical_accuracy: 0.6357\n",
      "Epoch 106/5000\n",
      "32/32 [==============================] - 17s 534ms/step - loss: 4.7645 - sparse_categorical_accuracy: 0.6320 - val_loss: 4.8315 - val_sparse_categorical_accuracy: 0.6316\n",
      "Epoch 107/5000\n",
      "32/32 [==============================] - 15s 489ms/step - loss: 4.7390 - sparse_categorical_accuracy: 0.6294 - val_loss: 4.8349 - val_sparse_categorical_accuracy: 0.6282\n",
      "Epoch 108/5000\n",
      "32/32 [==============================] - 16s 490ms/step - loss: 4.7755 - sparse_categorical_accuracy: 0.6241 - val_loss: 4.8775 - val_sparse_categorical_accuracy: 0.6330\n",
      "Epoch 109/5000\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 4.7485 - sparse_categorical_accuracy: 0.6183 - val_loss: 4.8500 - val_sparse_categorical_accuracy: 0.6187\n",
      "Epoch 110/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7664 - sparse_categorical_accuracy: 0.6286INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0110.ckpt/assets\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 4.7662 - sparse_categorical_accuracy: 0.6284 - val_loss: 4.8432 - val_sparse_categorical_accuracy: 0.6375\n",
      "Epoch 111/5000\n",
      "32/32 [==============================] - 17s 524ms/step - loss: 4.7602 - sparse_categorical_accuracy: 0.6336 - val_loss: 4.8493 - val_sparse_categorical_accuracy: 0.6301\n",
      "Epoch 112/5000\n",
      "32/32 [==============================] - 17s 527ms/step - loss: 4.7422 - sparse_categorical_accuracy: 0.6230 - val_loss: 4.8545 - val_sparse_categorical_accuracy: 0.6142\n",
      "Epoch 113/5000\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.7692 - sparse_categorical_accuracy: 0.6263 - val_loss: 4.8543 - val_sparse_categorical_accuracy: 0.6315\n",
      "Epoch 114/5000\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 4.7600 - sparse_categorical_accuracy: 0.6371 - val_loss: 4.8456 - val_sparse_categorical_accuracy: 0.6265\n",
      "Epoch 115/5000\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 4.7397 - sparse_categorical_accuracy: 0.6305 - val_loss: 4.8740 - val_sparse_categorical_accuracy: 0.6297\n",
      "Epoch 116/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7664 - sparse_categorical_accuracy: 0.6337 - val_loss: 4.8773 - val_sparse_categorical_accuracy: 0.6326\n",
      "Epoch 117/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7481 - sparse_categorical_accuracy: 0.6209 - val_loss: 4.8310 - val_sparse_categorical_accuracy: 0.6318\n",
      "Epoch 118/5000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 4.7661 - sparse_categorical_accuracy: 0.6273 - val_loss: 4.8599 - val_sparse_categorical_accuracy: 0.6248\n",
      "Epoch 119/5000\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 4.7691 - sparse_categorical_accuracy: 0.6306 - val_loss: 4.8537 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 120/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7360 - sparse_categorical_accuracy: 0.6298INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0120.ckpt/assets\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 4.7361 - sparse_categorical_accuracy: 0.6308 - val_loss: 4.8569 - val_sparse_categorical_accuracy: 0.6294\n",
      "Epoch 121/5000\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 4.7596 - sparse_categorical_accuracy: 0.6339 - val_loss: 4.8608 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 122/5000\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 4.7659 - sparse_categorical_accuracy: 0.6317 - val_loss: 4.8427 - val_sparse_categorical_accuracy: 0.6329\n",
      "Epoch 123/5000\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 4.7382 - sparse_categorical_accuracy: 0.6282 - val_loss: 4.8590 - val_sparse_categorical_accuracy: 0.6228\n",
      "Epoch 124/5000\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 4.7629 - sparse_categorical_accuracy: 0.6329 - val_loss: 4.8401 - val_sparse_categorical_accuracy: 0.6330\n",
      "Epoch 125/5000\n",
      "32/32 [==============================] - 16s 487ms/step - loss: 4.7612 - sparse_categorical_accuracy: 0.6359 - val_loss: 4.8495 - val_sparse_categorical_accuracy: 0.6392\n",
      "Epoch 126/5000\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 4.7339 - sparse_categorical_accuracy: 0.6308 - val_loss: 4.8330 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 127/5000\n",
      "32/32 [==============================] - 16s 504ms/step - loss: 4.7638 - sparse_categorical_accuracy: 0.6338 - val_loss: 4.8539 - val_sparse_categorical_accuracy: 0.6215\n",
      "Epoch 128/5000\n",
      "32/32 [==============================] - 16s 493ms/step - loss: 4.7314 - sparse_categorical_accuracy: 0.6393 - val_loss: 4.8382 - val_sparse_categorical_accuracy: 0.6171\n",
      "Epoch 129/5000\n",
      "32/32 [==============================] - 15s 465ms/step - loss: 4.7733 - sparse_categorical_accuracy: 0.6193 - val_loss: 4.8432 - val_sparse_categorical_accuracy: 0.6337\n",
      "Epoch 130/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7577 - sparse_categorical_accuracy: 0.6405INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0130.ckpt/assets\n",
      "32/32 [==============================] - 23s 744ms/step - loss: 4.7582 - sparse_categorical_accuracy: 0.6407 - val_loss: 4.8265 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 131/5000\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 4.7349 - sparse_categorical_accuracy: 0.6323 - val_loss: 4.8433 - val_sparse_categorical_accuracy: 0.6309\n",
      "Epoch 132/5000\n",
      "32/32 [==============================] - 16s 518ms/step - loss: 4.7598 - sparse_categorical_accuracy: 0.6357 - val_loss: 4.8379 - val_sparse_categorical_accuracy: 0.6277\n",
      "Epoch 133/5000\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 4.7635 - sparse_categorical_accuracy: 0.6307 - val_loss: 4.8374 - val_sparse_categorical_accuracy: 0.6277\n",
      "Epoch 134/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7382 - sparse_categorical_accuracy: 0.6346 - val_loss: 4.8435 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 135/5000\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 4.7684 - sparse_categorical_accuracy: 0.6257 - val_loss: 4.8457 - val_sparse_categorical_accuracy: 0.6304\n",
      "Epoch 136/5000\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 4.7264 - sparse_categorical_accuracy: 0.6436 - val_loss: 4.8265 - val_sparse_categorical_accuracy: 0.6153\n",
      "Epoch 137/5000\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 4.7595 - sparse_categorical_accuracy: 0.6371 - val_loss: 4.8388 - val_sparse_categorical_accuracy: 0.6133\n",
      "Epoch 138/5000\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.7668 - sparse_categorical_accuracy: 0.6317 - val_loss: 4.8366 - val_sparse_categorical_accuracy: 0.6333\n",
      "Epoch 139/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7315 - sparse_categorical_accuracy: 0.6364 - val_loss: 4.8275 - val_sparse_categorical_accuracy: 0.6298\n",
      "Epoch 140/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7567 - sparse_categorical_accuracy: 0.6379INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0140.ckpt/assets\n",
      "32/32 [==============================] - 27s 849ms/step - loss: 4.7568 - sparse_categorical_accuracy: 0.6369 - val_loss: 4.8135 - val_sparse_categorical_accuracy: 0.6297\n",
      "Epoch 141/5000\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 4.7543 - sparse_categorical_accuracy: 0.6375 - val_loss: 4.8314 - val_sparse_categorical_accuracy: 0.6327\n",
      "Epoch 142/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7371 - sparse_categorical_accuracy: 0.6280 - val_loss: 4.8449 - val_sparse_categorical_accuracy: 0.6260\n",
      "Epoch 143/5000\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 4.7608 - sparse_categorical_accuracy: 0.6352 - val_loss: 4.8204 - val_sparse_categorical_accuracy: 0.6334\n",
      "Epoch 144/5000\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 4.7568 - sparse_categorical_accuracy: 0.6390 - val_loss: 4.8376 - val_sparse_categorical_accuracy: 0.6155\n",
      "Epoch 145/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7354 - sparse_categorical_accuracy: 0.6348 - val_loss: 4.8241 - val_sparse_categorical_accuracy: 0.6315\n",
      "Epoch 146/5000\n",
      "32/32 [==============================] - 17s 548ms/step - loss: 4.7614 - sparse_categorical_accuracy: 0.6307 - val_loss: 4.8298 - val_sparse_categorical_accuracy: 0.6310\n",
      "Epoch 147/5000\n",
      "32/32 [==============================] - 17s 535ms/step - loss: 4.7366 - sparse_categorical_accuracy: 0.6324 - val_loss: 4.8233 - val_sparse_categorical_accuracy: 0.6251\n",
      "Epoch 148/5000\n",
      "32/32 [==============================] - 15s 469ms/step - loss: 4.7570 - sparse_categorical_accuracy: 0.6340 - val_loss: 4.8112 - val_sparse_categorical_accuracy: 0.6383\n",
      "Epoch 149/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7576 - sparse_categorical_accuracy: 0.6398 - val_loss: 4.8237 - val_sparse_categorical_accuracy: 0.6369\n",
      "Epoch 150/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7274 - sparse_categorical_accuracy: 0.6371INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0150.ckpt/assets\n",
      "32/32 [==============================] - 23s 741ms/step - loss: 4.7285 - sparse_categorical_accuracy: 0.6360 - val_loss: 4.8333 - val_sparse_categorical_accuracy: 0.6129\n",
      "Epoch 151/5000\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 4.7655 - sparse_categorical_accuracy: 0.6293 - val_loss: 4.8121 - val_sparse_categorical_accuracy: 0.6315\n",
      "Epoch 152/5000\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 4.7551 - sparse_categorical_accuracy: 0.6421 - val_loss: 4.8375 - val_sparse_categorical_accuracy: 0.6277\n",
      "Epoch 153/5000\n",
      "32/32 [==============================] - 16s 517ms/step - loss: 4.7312 - sparse_categorical_accuracy: 0.6404 - val_loss: 4.8481 - val_sparse_categorical_accuracy: 0.6146\n",
      "Epoch 154/5000\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 4.7576 - sparse_categorical_accuracy: 0.6373 - val_loss: 4.7997 - val_sparse_categorical_accuracy: 0.6209\n",
      "Epoch 155/5000\n",
      "32/32 [==============================] - 17s 514ms/step - loss: 4.7388 - sparse_categorical_accuracy: 0.6256 - val_loss: 4.8356 - val_sparse_categorical_accuracy: 0.6281\n",
      "Epoch 156/5000\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 4.7528 - sparse_categorical_accuracy: 0.6419 - val_loss: 4.8326 - val_sparse_categorical_accuracy: 0.6293\n",
      "Epoch 157/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7573 - sparse_categorical_accuracy: 0.6416 - val_loss: 4.8178 - val_sparse_categorical_accuracy: 0.6317\n",
      "Epoch 158/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7319 - sparse_categorical_accuracy: 0.6348 - val_loss: 4.8431 - val_sparse_categorical_accuracy: 0.6152\n",
      "Epoch 159/5000\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 4.7489 - sparse_categorical_accuracy: 0.6438 - val_loss: 4.8376 - val_sparse_categorical_accuracy: 0.6158\n",
      "Epoch 160/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7573 - sparse_categorical_accuracy: 0.6296INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0160.ckpt/assets\n",
      "32/32 [==============================] - 28s 877ms/step - loss: 4.7571 - sparse_categorical_accuracy: 0.6302 - val_loss: 4.8345 - val_sparse_categorical_accuracy: 0.6381\n",
      "Epoch 161/5000\n",
      "32/32 [==============================] - 15s 468ms/step - loss: 4.7257 - sparse_categorical_accuracy: 0.6417 - val_loss: 4.8122 - val_sparse_categorical_accuracy: 0.6374\n",
      "Epoch 162/5000\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 4.7526 - sparse_categorical_accuracy: 0.6429 - val_loss: 4.8075 - val_sparse_categorical_accuracy: 0.6351\n",
      "Epoch 163/5000\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 4.7563 - sparse_categorical_accuracy: 0.6371 - val_loss: 4.8276 - val_sparse_categorical_accuracy: 0.6411\n",
      "Epoch 164/5000\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 4.7248 - sparse_categorical_accuracy: 0.6431 - val_loss: 4.7982 - val_sparse_categorical_accuracy: 0.6317\n",
      "Epoch 165/5000\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 4.7692 - sparse_categorical_accuracy: 0.6288 - val_loss: 4.8073 - val_sparse_categorical_accuracy: 0.6352\n",
      "Epoch 166/5000\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 4.7303 - sparse_categorical_accuracy: 0.6449 - val_loss: 4.8351 - val_sparse_categorical_accuracy: 0.6322\n",
      "Epoch 167/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7531 - sparse_categorical_accuracy: 0.6398 - val_loss: 4.8097 - val_sparse_categorical_accuracy: 0.6384\n",
      "Epoch 168/5000\n",
      "32/32 [==============================] - 16s 505ms/step - loss: 4.7562 - sparse_categorical_accuracy: 0.6366 - val_loss: 4.8015 - val_sparse_categorical_accuracy: 0.6317\n",
      "Epoch 169/5000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 4.7179 - sparse_categorical_accuracy: 0.6535 - val_loss: 4.8328 - val_sparse_categorical_accuracy: 0.6321\n",
      "Epoch 170/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7505 - sparse_categorical_accuracy: 0.6425INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0170.ckpt/assets\n",
      "32/32 [==============================] - 24s 750ms/step - loss: 4.7519 - sparse_categorical_accuracy: 0.6414 - val_loss: 4.8247 - val_sparse_categorical_accuracy: 0.6423\n",
      "Epoch 171/5000\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 4.7552 - sparse_categorical_accuracy: 0.6437 - val_loss: 4.8246 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 172/5000\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 4.7279 - sparse_categorical_accuracy: 0.6347 - val_loss: 4.7993 - val_sparse_categorical_accuracy: 0.6240\n",
      "Epoch 173/5000\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 4.7517 - sparse_categorical_accuracy: 0.6432 - val_loss: 4.8102 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 174/5000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 4.7280 - sparse_categorical_accuracy: 0.6416 - val_loss: 4.7899 - val_sparse_categorical_accuracy: 0.6319\n",
      "Epoch 175/5000\n",
      "32/32 [==============================] - 16s 504ms/step - loss: 4.7615 - sparse_categorical_accuracy: 0.6308 - val_loss: 4.8083 - val_sparse_categorical_accuracy: 0.6298\n",
      "Epoch 176/5000\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 4.7517 - sparse_categorical_accuracy: 0.6488 - val_loss: 4.8137 - val_sparse_categorical_accuracy: 0.6393\n",
      "Epoch 177/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7202 - sparse_categorical_accuracy: 0.6524 - val_loss: 4.7786 - val_sparse_categorical_accuracy: 0.6370\n",
      "Epoch 178/5000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 4.7521 - sparse_categorical_accuracy: 0.6437 - val_loss: 4.8105 - val_sparse_categorical_accuracy: 0.6282\n",
      "Epoch 179/5000\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 4.7482 - sparse_categorical_accuracy: 0.6490 - val_loss: 4.8075 - val_sparse_categorical_accuracy: 0.6412\n",
      "Epoch 180/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7253 - sparse_categorical_accuracy: 0.6407INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0180.ckpt/assets\n",
      "32/32 [==============================] - 22s 703ms/step - loss: 4.7258 - sparse_categorical_accuracy: 0.6411 - val_loss: 4.7851 - val_sparse_categorical_accuracy: 0.6360\n",
      "Epoch 181/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7607 - sparse_categorical_accuracy: 0.6307 - val_loss: 4.8074 - val_sparse_categorical_accuracy: 0.6339\n",
      "Epoch 182/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7586 - sparse_categorical_accuracy: 0.6339 - val_loss: 4.8153 - val_sparse_categorical_accuracy: 0.6393\n",
      "Epoch 183/5000\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 4.7217 - sparse_categorical_accuracy: 0.6372 - val_loss: 4.7951 - val_sparse_categorical_accuracy: 0.6353\n",
      "Epoch 184/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7518 - sparse_categorical_accuracy: 0.6422 - val_loss: 4.7926 - val_sparse_categorical_accuracy: 0.6361\n",
      "Epoch 185/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7188 - sparse_categorical_accuracy: 0.6479 - val_loss: 4.7972 - val_sparse_categorical_accuracy: 0.6342\n",
      "Epoch 186/5000\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 4.7523 - sparse_categorical_accuracy: 0.6453 - val_loss: 4.7958 - val_sparse_categorical_accuracy: 0.6316\n",
      "Epoch 187/5000\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 4.7480 - sparse_categorical_accuracy: 0.6492 - val_loss: 4.7840 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 188/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7238 - sparse_categorical_accuracy: 0.6445 - val_loss: 4.7955 - val_sparse_categorical_accuracy: 0.6345\n",
      "Epoch 189/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7490 - sparse_categorical_accuracy: 0.6431 - val_loss: 4.7961 - val_sparse_categorical_accuracy: 0.6379\n",
      "Epoch 190/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7501 - sparse_categorical_accuracy: 0.6452INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0190.ckpt/assets\n",
      "32/32 [==============================] - 23s 735ms/step - loss: 4.7496 - sparse_categorical_accuracy: 0.6457 - val_loss: 4.8007 - val_sparse_categorical_accuracy: 0.6316\n",
      "Epoch 191/5000\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 4.7230 - sparse_categorical_accuracy: 0.6449 - val_loss: 4.7890 - val_sparse_categorical_accuracy: 0.6273\n",
      "Epoch 192/5000\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 4.7534 - sparse_categorical_accuracy: 0.6441 - val_loss: 4.7927 - val_sparse_categorical_accuracy: 0.6410\n",
      "Epoch 193/5000\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 4.7524 - sparse_categorical_accuracy: 0.6449 - val_loss: 4.8005 - val_sparse_categorical_accuracy: 0.6367\n",
      "Epoch 194/5000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 4.7222 - sparse_categorical_accuracy: 0.6424 - val_loss: 4.7996 - val_sparse_categorical_accuracy: 0.6410\n",
      "Epoch 195/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7517 - sparse_categorical_accuracy: 0.6369 - val_loss: 4.8236 - val_sparse_categorical_accuracy: 0.6291\n",
      "Epoch 196/5000\n",
      "32/32 [==============================] - 14s 433ms/step - loss: 4.7221 - sparse_categorical_accuracy: 0.6433 - val_loss: 4.8014 - val_sparse_categorical_accuracy: 0.6425\n",
      "Epoch 197/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7475 - sparse_categorical_accuracy: 0.6478 - val_loss: 4.7957 - val_sparse_categorical_accuracy: 0.6327\n",
      "Epoch 198/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7562 - sparse_categorical_accuracy: 0.6411 - val_loss: 4.7906 - val_sparse_categorical_accuracy: 0.6251\n",
      "Epoch 199/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7178 - sparse_categorical_accuracy: 0.6487 - val_loss: 4.7990 - val_sparse_categorical_accuracy: 0.6412\n",
      "Epoch 200/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7608 - sparse_categorical_accuracy: 0.6386INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0200.ckpt/assets\n",
      "32/32 [==============================] - 23s 717ms/step - loss: 4.7592 - sparse_categorical_accuracy: 0.6403 - val_loss: 4.7849 - val_sparse_categorical_accuracy: 0.6384\n",
      "Epoch 201/5000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 4.7485 - sparse_categorical_accuracy: 0.6466 - val_loss: 4.7853 - val_sparse_categorical_accuracy: 0.6391\n",
      "Epoch 202/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7275 - sparse_categorical_accuracy: 0.6409 - val_loss: 4.7887 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 203/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7433 - sparse_categorical_accuracy: 0.6475 - val_loss: 4.7794 - val_sparse_categorical_accuracy: 0.6341\n",
      "Epoch 204/5000\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 4.7174 - sparse_categorical_accuracy: 0.6464 - val_loss: 4.7811 - val_sparse_categorical_accuracy: 0.6412\n",
      "Epoch 205/5000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 4.7385 - sparse_categorical_accuracy: 0.6549 - val_loss: 4.7760 - val_sparse_categorical_accuracy: 0.6400\n",
      "Epoch 206/5000\n",
      "32/32 [==============================] - 16s 493ms/step - loss: 4.7554 - sparse_categorical_accuracy: 0.6363 - val_loss: 4.8049 - val_sparse_categorical_accuracy: 0.6270\n",
      "Epoch 207/5000\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 4.7146 - sparse_categorical_accuracy: 0.6555 - val_loss: 4.7820 - val_sparse_categorical_accuracy: 0.6342\n",
      "Epoch 208/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7432 - sparse_categorical_accuracy: 0.6486 - val_loss: 4.7824 - val_sparse_categorical_accuracy: 0.6415\n",
      "Epoch 209/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7500 - sparse_categorical_accuracy: 0.6392 - val_loss: 4.8388 - val_sparse_categorical_accuracy: 0.6136\n",
      "Epoch 210/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7225 - sparse_categorical_accuracy: 0.6421INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0210.ckpt/assets\n",
      "32/32 [==============================] - 22s 709ms/step - loss: 4.7243 - sparse_categorical_accuracy: 0.6412 - val_loss: 4.7940 - val_sparse_categorical_accuracy: 0.6230\n",
      "Epoch 211/5000\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 4.7467 - sparse_categorical_accuracy: 0.6441 - val_loss: 4.7644 - val_sparse_categorical_accuracy: 0.6355\n",
      "Epoch 212/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7488 - sparse_categorical_accuracy: 0.6466 - val_loss: 4.7719 - val_sparse_categorical_accuracy: 0.6411\n",
      "Epoch 213/5000\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 4.7180 - sparse_categorical_accuracy: 0.6525 - val_loss: 4.7702 - val_sparse_categorical_accuracy: 0.6399\n",
      "Epoch 214/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7464 - sparse_categorical_accuracy: 0.6446 - val_loss: 4.7680 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 215/5000\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 4.7111 - sparse_categorical_accuracy: 0.6558 - val_loss: 4.7819 - val_sparse_categorical_accuracy: 0.6345\n",
      "Epoch 216/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7523 - sparse_categorical_accuracy: 0.6432 - val_loss: 4.7805 - val_sparse_categorical_accuracy: 0.6504\n",
      "Epoch 217/5000\n",
      "32/32 [==============================] - 21s 665ms/step - loss: 4.7425 - sparse_categorical_accuracy: 0.6495 - val_loss: 4.7884 - val_sparse_categorical_accuracy: 0.6394\n",
      "Epoch 218/5000\n",
      "32/32 [==============================] - 22s 688ms/step - loss: 4.7228 - sparse_categorical_accuracy: 0.6443 - val_loss: 4.7696 - val_sparse_categorical_accuracy: 0.6380\n",
      "Epoch 219/5000\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.7364 - sparse_categorical_accuracy: 0.6594 - val_loss: 4.7879 - val_sparse_categorical_accuracy: 0.6350\n",
      "Epoch 220/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7535 - sparse_categorical_accuracy: 0.6353INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0220.ckpt/assets\n",
      "32/32 [==============================] - 26s 834ms/step - loss: 4.7545 - sparse_categorical_accuracy: 0.6342 - val_loss: 4.7989 - val_sparse_categorical_accuracy: 0.6401\n",
      "Epoch 221/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7190 - sparse_categorical_accuracy: 0.6508 - val_loss: 4.7714 - val_sparse_categorical_accuracy: 0.6432\n",
      "Epoch 222/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7478 - sparse_categorical_accuracy: 0.6478 - val_loss: 4.7787 - val_sparse_categorical_accuracy: 0.6396\n",
      "Epoch 223/5000\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 4.7196 - sparse_categorical_accuracy: 0.6406 - val_loss: 4.7749 - val_sparse_categorical_accuracy: 0.6421\n",
      "Epoch 224/5000\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 4.7417 - sparse_categorical_accuracy: 0.6510 - val_loss: 4.7796 - val_sparse_categorical_accuracy: 0.6502\n",
      "Epoch 225/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7462 - sparse_categorical_accuracy: 0.6505 - val_loss: 4.7799 - val_sparse_categorical_accuracy: 0.6458\n",
      "Epoch 226/5000\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 4.7189 - sparse_categorical_accuracy: 0.6469 - val_loss: 4.7625 - val_sparse_categorical_accuracy: 0.6449\n",
      "Epoch 227/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7543 - sparse_categorical_accuracy: 0.6407 - val_loss: 4.7764 - val_sparse_categorical_accuracy: 0.6403\n",
      "Epoch 228/5000\n",
      "32/32 [==============================] - 14s 454ms/step - loss: 4.7387 - sparse_categorical_accuracy: 0.6516 - val_loss: 4.7656 - val_sparse_categorical_accuracy: 0.6580\n",
      "Epoch 229/5000\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 4.7213 - sparse_categorical_accuracy: 0.6463 - val_loss: 4.7767 - val_sparse_categorical_accuracy: 0.6476\n",
      "Epoch 230/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7354 - sparse_categorical_accuracy: 0.6556INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0230.ckpt/assets\n",
      "32/32 [==============================] - 22s 711ms/step - loss: 4.7371 - sparse_categorical_accuracy: 0.6565 - val_loss: 4.7768 - val_sparse_categorical_accuracy: 0.6438\n",
      "Epoch 231/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7409 - sparse_categorical_accuracy: 0.6490 - val_loss: 4.7672 - val_sparse_categorical_accuracy: 0.6404\n",
      "Epoch 232/5000\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 4.7227 - sparse_categorical_accuracy: 0.6459 - val_loss: 4.7728 - val_sparse_categorical_accuracy: 0.6372\n",
      "Epoch 233/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7452 - sparse_categorical_accuracy: 0.6569 - val_loss: 4.7683 - val_sparse_categorical_accuracy: 0.6458\n",
      "Epoch 234/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7140 - sparse_categorical_accuracy: 0.6541 - val_loss: 4.7836 - val_sparse_categorical_accuracy: 0.6458\n",
      "Epoch 235/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7417 - sparse_categorical_accuracy: 0.6513 - val_loss: 4.8024 - val_sparse_categorical_accuracy: 0.6467\n",
      "Epoch 236/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7355 - sparse_categorical_accuracy: 0.6553 - val_loss: 4.7845 - val_sparse_categorical_accuracy: 0.6422\n",
      "Epoch 237/5000\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 4.7196 - sparse_categorical_accuracy: 0.6486 - val_loss: 4.7746 - val_sparse_categorical_accuracy: 0.6501\n",
      "Epoch 238/5000\n",
      "32/32 [==============================] - 17s 527ms/step - loss: 4.7336 - sparse_categorical_accuracy: 0.6583 - val_loss: 4.7884 - val_sparse_categorical_accuracy: 0.6426\n",
      "Epoch 239/5000\n",
      "32/32 [==============================] - 15s 483ms/step - loss: 4.7458 - sparse_categorical_accuracy: 0.6485 - val_loss: 4.7901 - val_sparse_categorical_accuracy: 0.6400\n",
      "Epoch 240/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7222 - sparse_categorical_accuracy: 0.6508INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0240.ckpt/assets\n",
      "32/32 [==============================] - 24s 763ms/step - loss: 4.7238 - sparse_categorical_accuracy: 0.6495 - val_loss: 4.7729 - val_sparse_categorical_accuracy: 0.6329\n",
      "Epoch 241/5000\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 4.7373 - sparse_categorical_accuracy: 0.6523 - val_loss: 4.7834 - val_sparse_categorical_accuracy: 0.6397\n",
      "Epoch 242/5000\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 4.7179 - sparse_categorical_accuracy: 0.6499 - val_loss: 4.8225 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 243/5000\n",
      "32/32 [==============================] - 16s 502ms/step - loss: 4.7444 - sparse_categorical_accuracy: 0.6449 - val_loss: 4.7895 - val_sparse_categorical_accuracy: 0.6430\n",
      "Epoch 244/5000\n",
      "32/32 [==============================] - 17s 533ms/step - loss: 4.7441 - sparse_categorical_accuracy: 0.6494 - val_loss: 4.8195 - val_sparse_categorical_accuracy: 0.6416\n",
      "Epoch 245/5000\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 4.7194 - sparse_categorical_accuracy: 0.6497 - val_loss: 4.7713 - val_sparse_categorical_accuracy: 0.6488\n",
      "Epoch 246/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7349 - sparse_categorical_accuracy: 0.6563 - val_loss: 4.7811 - val_sparse_categorical_accuracy: 0.6378\n",
      "Epoch 247/5000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 4.7440 - sparse_categorical_accuracy: 0.6504 - val_loss: 4.7935 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 248/5000\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 4.7259 - sparse_categorical_accuracy: 0.6401 - val_loss: 4.7647 - val_sparse_categorical_accuracy: 0.6419\n",
      "Epoch 249/5000\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 4.7351 - sparse_categorical_accuracy: 0.6574 - val_loss: 4.7860 - val_sparse_categorical_accuracy: 0.6504\n",
      "Epoch 250/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7504 - sparse_categorical_accuracy: 0.6420INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0250.ckpt/assets\n",
      "32/32 [==============================] - 25s 797ms/step - loss: 4.7487 - sparse_categorical_accuracy: 0.6449 - val_loss: 4.7695 - val_sparse_categorical_accuracy: 0.6384\n",
      "Epoch 251/5000\n",
      "32/32 [==============================] - 15s 472ms/step - loss: 4.7238 - sparse_categorical_accuracy: 0.6446 - val_loss: 4.7731 - val_sparse_categorical_accuracy: 0.6427\n",
      "Epoch 252/5000\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 4.7403 - sparse_categorical_accuracy: 0.6582 - val_loss: 4.7679 - val_sparse_categorical_accuracy: 0.6427\n",
      "Epoch 253/5000\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 4.7146 - sparse_categorical_accuracy: 0.6477 - val_loss: 4.7908 - val_sparse_categorical_accuracy: 0.6329\n",
      "Epoch 254/5000\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 4.7449 - sparse_categorical_accuracy: 0.6474 - val_loss: 4.7691 - val_sparse_categorical_accuracy: 0.6427\n",
      "Epoch 255/5000\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 4.7363 - sparse_categorical_accuracy: 0.6584 - val_loss: 4.7700 - val_sparse_categorical_accuracy: 0.6366\n",
      "Epoch 256/5000\n",
      "32/32 [==============================] - 15s 477ms/step - loss: 4.7189 - sparse_categorical_accuracy: 0.6484 - val_loss: 4.7655 - val_sparse_categorical_accuracy: 0.6350\n",
      "Epoch 257/5000\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 4.7558 - sparse_categorical_accuracy: 0.6365 - val_loss: 4.7679 - val_sparse_categorical_accuracy: 0.6388\n",
      "Epoch 258/5000\n",
      "32/32 [==============================] - 14s 455ms/step - loss: 4.7322 - sparse_categorical_accuracy: 0.6603 - val_loss: 4.7689 - val_sparse_categorical_accuracy: 0.6340\n",
      "Epoch 259/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7156 - sparse_categorical_accuracy: 0.6509 - val_loss: 4.7686 - val_sparse_categorical_accuracy: 0.6425\n",
      "Epoch 260/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7421 - sparse_categorical_accuracy: 0.6539INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0260.ckpt/assets\n",
      "32/32 [==============================] - 24s 751ms/step - loss: 4.7425 - sparse_categorical_accuracy: 0.6540 - val_loss: 4.7975 - val_sparse_categorical_accuracy: 0.6459\n",
      "Epoch 261/5000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 4.7106 - sparse_categorical_accuracy: 0.6548 - val_loss: 4.7731 - val_sparse_categorical_accuracy: 0.6484\n",
      "Epoch 262/5000\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 4.7460 - sparse_categorical_accuracy: 0.6474 - val_loss: 4.7761 - val_sparse_categorical_accuracy: 0.6530\n",
      "Epoch 263/5000\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 4.7428 - sparse_categorical_accuracy: 0.6501 - val_loss: 4.7975 - val_sparse_categorical_accuracy: 0.6532\n",
      "Epoch 264/5000\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 4.7077 - sparse_categorical_accuracy: 0.6568 - val_loss: 4.7642 - val_sparse_categorical_accuracy: 0.6486\n",
      "Epoch 265/5000\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 4.7427 - sparse_categorical_accuracy: 0.6530 - val_loss: 4.7810 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 266/5000\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 4.7466 - sparse_categorical_accuracy: 0.6462 - val_loss: 4.7853 - val_sparse_categorical_accuracy: 0.6382\n",
      "Epoch 267/5000\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 4.7152 - sparse_categorical_accuracy: 0.6476 - val_loss: 4.7777 - val_sparse_categorical_accuracy: 0.6372\n",
      "Epoch 268/5000\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 4.7391 - sparse_categorical_accuracy: 0.6497 - val_loss: 4.7702 - val_sparse_categorical_accuracy: 0.6417\n",
      "Epoch 269/5000\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 4.7411 - sparse_categorical_accuracy: 0.6467 - val_loss: 4.7687 - val_sparse_categorical_accuracy: 0.6525\n",
      "Epoch 270/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7042 - sparse_categorical_accuracy: 0.6585INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0270.ckpt/assets\n",
      "32/32 [==============================] - 23s 734ms/step - loss: 4.7058 - sparse_categorical_accuracy: 0.6581 - val_loss: 4.7792 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 271/5000\n",
      "32/32 [==============================] - 14s 454ms/step - loss: 4.7386 - sparse_categorical_accuracy: 0.6533 - val_loss: 4.8035 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 272/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7178 - sparse_categorical_accuracy: 0.6452 - val_loss: 4.7896 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 273/5000\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 4.7369 - sparse_categorical_accuracy: 0.6558 - val_loss: 4.7784 - val_sparse_categorical_accuracy: 0.6456\n",
      "Epoch 274/5000\n",
      "32/32 [==============================] - 14s 455ms/step - loss: 4.7355 - sparse_categorical_accuracy: 0.6567 - val_loss: 4.7856 - val_sparse_categorical_accuracy: 0.6479\n",
      "Epoch 275/5000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 4.7057 - sparse_categorical_accuracy: 0.6553 - val_loss: 4.7715 - val_sparse_categorical_accuracy: 0.6340\n",
      "Epoch 276/5000\n",
      "32/32 [==============================] - 14s 454ms/step - loss: 4.7390 - sparse_categorical_accuracy: 0.6532 - val_loss: 4.7699 - val_sparse_categorical_accuracy: 0.6489\n",
      "Epoch 277/5000\n",
      "32/32 [==============================] - 16s 490ms/step - loss: 4.7425 - sparse_categorical_accuracy: 0.6529 - val_loss: 4.7759 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 278/5000\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 4.7076 - sparse_categorical_accuracy: 0.6502 - val_loss: 4.8064 - val_sparse_categorical_accuracy: 0.6414\n",
      "Epoch 279/5000\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 4.7351 - sparse_categorical_accuracy: 0.6549 - val_loss: 4.8120 - val_sparse_categorical_accuracy: 0.6361\n",
      "Epoch 280/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7441 - sparse_categorical_accuracy: 0.6494INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0280.ckpt/assets\n",
      "32/32 [==============================] - 23s 718ms/step - loss: 4.7450 - sparse_categorical_accuracy: 0.6481 - val_loss: 4.7752 - val_sparse_categorical_accuracy: 0.6461\n",
      "Epoch 281/5000\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 4.7129 - sparse_categorical_accuracy: 0.6545 - val_loss: 4.7742 - val_sparse_categorical_accuracy: 0.6358\n",
      "Epoch 282/5000\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 4.7429 - sparse_categorical_accuracy: 0.6484 - val_loss: 4.7859 - val_sparse_categorical_accuracy: 0.6415\n",
      "Epoch 283/5000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 4.7099 - sparse_categorical_accuracy: 0.6615 - val_loss: 4.7766 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 284/5000\n",
      "32/32 [==============================] - 15s 469ms/step - loss: 4.7366 - sparse_categorical_accuracy: 0.6605 - val_loss: 4.7861 - val_sparse_categorical_accuracy: 0.6468\n",
      "Epoch 285/5000\n",
      "32/32 [==============================] - 15s 468ms/step - loss: 4.7410 - sparse_categorical_accuracy: 0.6509 - val_loss: 4.7858 - val_sparse_categorical_accuracy: 0.6412\n",
      "Epoch 286/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7028 - sparse_categorical_accuracy: 0.6553 - val_loss: 4.7505 - val_sparse_categorical_accuracy: 0.6538\n",
      "Epoch 287/5000\n",
      "32/32 [==============================] - 15s 481ms/step - loss: 4.7359 - sparse_categorical_accuracy: 0.6600 - val_loss: 4.7885 - val_sparse_categorical_accuracy: 0.6371\n",
      "Epoch 288/5000\n",
      "32/32 [==============================] - 15s 478ms/step - loss: 4.7420 - sparse_categorical_accuracy: 0.6486 - val_loss: 4.7927 - val_sparse_categorical_accuracy: 0.6262\n",
      "Epoch 289/5000\n",
      "32/32 [==============================] - 15s 477ms/step - loss: 4.7074 - sparse_categorical_accuracy: 0.6566 - val_loss: 4.7866 - val_sparse_categorical_accuracy: 0.6405\n",
      "Epoch 290/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7443 - sparse_categorical_accuracy: 0.6484INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0290.ckpt/assets\n",
      "32/32 [==============================] - 27s 855ms/step - loss: 4.7457 - sparse_categorical_accuracy: 0.6463 - val_loss: 4.7775 - val_sparse_categorical_accuracy: 0.6421\n",
      "Epoch 291/5000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 4.7086 - sparse_categorical_accuracy: 0.6536 - val_loss: 4.7710 - val_sparse_categorical_accuracy: 0.6389\n",
      "Epoch 292/5000\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 4.7392 - sparse_categorical_accuracy: 0.6525 - val_loss: 4.7805 - val_sparse_categorical_accuracy: 0.6376\n",
      "Epoch 293/5000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 4.7319 - sparse_categorical_accuracy: 0.6618 - val_loss: 4.7764 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 294/5000\n",
      "32/32 [==============================] - 17s 528ms/step - loss: 4.7182 - sparse_categorical_accuracy: 0.6515 - val_loss: 4.7655 - val_sparse_categorical_accuracy: 0.6495\n",
      "Epoch 295/5000\n",
      "32/32 [==============================] - 15s 468ms/step - loss: 4.7377 - sparse_categorical_accuracy: 0.6581 - val_loss: 4.7534 - val_sparse_categorical_accuracy: 0.6396\n",
      "Epoch 296/5000\n",
      "32/32 [==============================] - 16s 490ms/step - loss: 4.7381 - sparse_categorical_accuracy: 0.6569 - val_loss: 4.7627 - val_sparse_categorical_accuracy: 0.6421\n",
      "Epoch 297/5000\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 4.7124 - sparse_categorical_accuracy: 0.6578 - val_loss: 4.7675 - val_sparse_categorical_accuracy: 0.6513\n",
      "Epoch 298/5000\n",
      "32/32 [==============================] - 15s 470ms/step - loss: 4.7328 - sparse_categorical_accuracy: 0.6582 - val_loss: 4.7687 - val_sparse_categorical_accuracy: 0.6420\n",
      "Epoch 299/5000\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 4.7402 - sparse_categorical_accuracy: 0.6482 - val_loss: 4.7754 - val_sparse_categorical_accuracy: 0.6520\n",
      "Epoch 300/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7045 - sparse_categorical_accuracy: 0.6577INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0300.ckpt/assets\n",
      "32/32 [==============================] - 22s 705ms/step - loss: 4.7058 - sparse_categorical_accuracy: 0.6576 - val_loss: 4.7605 - val_sparse_categorical_accuracy: 0.6476\n",
      "Epoch 301/5000\n",
      "32/32 [==============================] - 14s 453ms/step - loss: 4.7324 - sparse_categorical_accuracy: 0.6592 - val_loss: 4.7729 - val_sparse_categorical_accuracy: 0.6466\n",
      "Epoch 302/5000\n",
      "32/32 [==============================] - 15s 466ms/step - loss: 4.7043 - sparse_categorical_accuracy: 0.6575 - val_loss: 4.7725 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 303/5000\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 4.7418 - sparse_categorical_accuracy: 0.6465 - val_loss: 4.7830 - val_sparse_categorical_accuracy: 0.6410\n",
      "Epoch 304/5000\n",
      "32/32 [==============================] - 15s 455ms/step - loss: 4.7395 - sparse_categorical_accuracy: 0.6522 - val_loss: 4.7808 - val_sparse_categorical_accuracy: 0.6416\n",
      "Epoch 305/5000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 4.7112 - sparse_categorical_accuracy: 0.6496 - val_loss: 4.7829 - val_sparse_categorical_accuracy: 0.6535\n",
      "Epoch 306/5000\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 4.7379 - sparse_categorical_accuracy: 0.6537 - val_loss: 4.7660 - val_sparse_categorical_accuracy: 0.6409\n",
      "Epoch 307/5000\n",
      "32/32 [==============================] - 15s 484ms/step - loss: 4.7246 - sparse_categorical_accuracy: 0.6691 - val_loss: 4.7719 - val_sparse_categorical_accuracy: 0.6435\n",
      "Epoch 308/5000\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 4.7040 - sparse_categorical_accuracy: 0.6606 - val_loss: 4.7633 - val_sparse_categorical_accuracy: 0.6465\n",
      "Epoch 309/5000\n",
      "32/32 [==============================] - 16s 498ms/step - loss: 4.7524 - sparse_categorical_accuracy: 0.6430 - val_loss: 4.7749 - val_sparse_categorical_accuracy: 0.6362\n",
      "Epoch 310/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7078 - sparse_categorical_accuracy: 0.6503INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0310.ckpt/assets\n",
      "32/32 [==============================] - 23s 721ms/step - loss: 4.7091 - sparse_categorical_accuracy: 0.6496 - val_loss: 4.7829 - val_sparse_categorical_accuracy: 0.6437\n",
      "Epoch 311/5000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 4.7326 - sparse_categorical_accuracy: 0.6598 - val_loss: 4.7978 - val_sparse_categorical_accuracy: 0.6505\n",
      "Epoch 312/5000\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 4.7360 - sparse_categorical_accuracy: 0.6565 - val_loss: 4.7695 - val_sparse_categorical_accuracy: 0.6418\n",
      "Epoch 313/5000\n",
      "32/32 [==============================] - 17s 531ms/step - loss: 4.7115 - sparse_categorical_accuracy: 0.6501 - val_loss: 4.7696 - val_sparse_categorical_accuracy: 0.6372\n",
      "Epoch 314/5000\n",
      "32/32 [==============================] - 19s 601ms/step - loss: 4.7306 - sparse_categorical_accuracy: 0.6582 - val_loss: 4.7617 - val_sparse_categorical_accuracy: 0.6386\n",
      "Epoch 315/5000\n",
      "32/32 [==============================] - 17s 539ms/step - loss: 4.7291 - sparse_categorical_accuracy: 0.6644 - val_loss: 4.7747 - val_sparse_categorical_accuracy: 0.6457\n",
      "Epoch 316/5000\n",
      "32/32 [==============================] - 17s 530ms/step - loss: 4.7053 - sparse_categorical_accuracy: 0.6614 - val_loss: 4.7780 - val_sparse_categorical_accuracy: 0.6312\n",
      "Epoch 317/5000\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 4.7378 - sparse_categorical_accuracy: 0.6548 - val_loss: 4.7733 - val_sparse_categorical_accuracy: 0.6461\n",
      "Epoch 318/5000\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.7336 - sparse_categorical_accuracy: 0.6618 - val_loss: 4.7578 - val_sparse_categorical_accuracy: 0.6518\n",
      "Epoch 319/5000\n",
      "32/32 [==============================] - 15s 479ms/step - loss: 4.6977 - sparse_categorical_accuracy: 0.6635 - val_loss: 4.7567 - val_sparse_categorical_accuracy: 0.6430\n",
      "Epoch 320/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7307 - sparse_categorical_accuracy: 0.6593INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0320.ckpt/assets\n",
      "32/32 [==============================] - 24s 751ms/step - loss: 4.7317 - sparse_categorical_accuracy: 0.6581 - val_loss: 4.7617 - val_sparse_categorical_accuracy: 0.6503\n",
      "Epoch 321/5000\n",
      "32/32 [==============================] - 17s 520ms/step - loss: 4.7074 - sparse_categorical_accuracy: 0.6532 - val_loss: 4.7877 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 322/5000\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 4.7290 - sparse_categorical_accuracy: 0.6623 - val_loss: 4.7761 - val_sparse_categorical_accuracy: 0.6502\n",
      "Epoch 323/5000\n",
      "32/32 [==============================] - 17s 530ms/step - loss: 4.7394 - sparse_categorical_accuracy: 0.6524 - val_loss: 4.7652 - val_sparse_categorical_accuracy: 0.6562\n",
      "Epoch 324/5000\n",
      "32/32 [==============================] - 16s 518ms/step - loss: 4.7107 - sparse_categorical_accuracy: 0.6505 - val_loss: 4.7733 - val_sparse_categorical_accuracy: 0.6397\n",
      "Epoch 325/5000\n",
      "32/32 [==============================] - 17s 530ms/step - loss: 4.7297 - sparse_categorical_accuracy: 0.6570 - val_loss: 4.8037 - val_sparse_categorical_accuracy: 0.6441\n",
      "Epoch 326/5000\n",
      "32/32 [==============================] - 17s 535ms/step - loss: 4.7345 - sparse_categorical_accuracy: 0.6546 - val_loss: 4.7661 - val_sparse_categorical_accuracy: 0.6495\n",
      "Epoch 327/5000\n",
      "32/32 [==============================] - 17s 522ms/step - loss: 4.7102 - sparse_categorical_accuracy: 0.6547 - val_loss: 4.7746 - val_sparse_categorical_accuracy: 0.6337\n",
      "Epoch 328/5000\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 4.7302 - sparse_categorical_accuracy: 0.6590 - val_loss: 4.7575 - val_sparse_categorical_accuracy: 0.6457\n",
      "Epoch 329/5000\n",
      "32/32 [==============================] - 17s 522ms/step - loss: 4.7069 - sparse_categorical_accuracy: 0.6571 - val_loss: 4.7627 - val_sparse_categorical_accuracy: 0.6470\n",
      "Epoch 330/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7335 - sparse_categorical_accuracy: 0.6537INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0330.ckpt/assets\n",
      "32/32 [==============================] - 25s 804ms/step - loss: 4.7317 - sparse_categorical_accuracy: 0.6554 - val_loss: 4.7549 - val_sparse_categorical_accuracy: 0.6513\n",
      "Epoch 331/5000\n",
      "32/32 [==============================] - 17s 528ms/step - loss: 4.7267 - sparse_categorical_accuracy: 0.6640 - val_loss: 4.7592 - val_sparse_categorical_accuracy: 0.6559\n",
      "Epoch 332/5000\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 4.7117 - sparse_categorical_accuracy: 0.6516 - val_loss: 4.7533 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 333/5000\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 4.7322 - sparse_categorical_accuracy: 0.6531 - val_loss: 4.7507 - val_sparse_categorical_accuracy: 0.6517\n",
      "Epoch 334/5000\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 4.7324 - sparse_categorical_accuracy: 0.6547 - val_loss: 4.7694 - val_sparse_categorical_accuracy: 0.6378\n",
      "Epoch 335/5000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 4.7150 - sparse_categorical_accuracy: 0.6486 - val_loss: 4.7805 - val_sparse_categorical_accuracy: 0.6456\n",
      "Epoch 336/5000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 4.7301 - sparse_categorical_accuracy: 0.6597 - val_loss: 4.7724 - val_sparse_categorical_accuracy: 0.6490\n",
      "Epoch 337/5000\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 4.7291 - sparse_categorical_accuracy: 0.6604 - val_loss: 4.7713 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 338/5000\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 4.7090 - sparse_categorical_accuracy: 0.6585 - val_loss: 4.7598 - val_sparse_categorical_accuracy: 0.6492\n",
      "Epoch 339/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7283 - sparse_categorical_accuracy: 0.6576 - val_loss: 4.7622 - val_sparse_categorical_accuracy: 0.6501\n",
      "Epoch 340/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7035 - sparse_categorical_accuracy: 0.6585INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0340.ckpt/assets\n",
      "32/32 [==============================] - 22s 703ms/step - loss: 4.7034 - sparse_categorical_accuracy: 0.6594 - val_loss: 4.7718 - val_sparse_categorical_accuracy: 0.6447\n",
      "Epoch 341/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7292 - sparse_categorical_accuracy: 0.6569 - val_loss: 4.7650 - val_sparse_categorical_accuracy: 0.6434\n",
      "Epoch 342/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7298 - sparse_categorical_accuracy: 0.6604 - val_loss: 4.7698 - val_sparse_categorical_accuracy: 0.6416\n",
      "Epoch 343/5000\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 4.7056 - sparse_categorical_accuracy: 0.6595 - val_loss: 4.7593 - val_sparse_categorical_accuracy: 0.6539\n",
      "Epoch 344/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7300 - sparse_categorical_accuracy: 0.6612 - val_loss: 4.7546 - val_sparse_categorical_accuracy: 0.6489\n",
      "Epoch 345/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7366 - sparse_categorical_accuracy: 0.6546 - val_loss: 4.7639 - val_sparse_categorical_accuracy: 0.6433\n",
      "Epoch 346/5000\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 4.7006 - sparse_categorical_accuracy: 0.6569 - val_loss: 4.7520 - val_sparse_categorical_accuracy: 0.6555\n",
      "Epoch 347/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7397 - sparse_categorical_accuracy: 0.6536 - val_loss: 4.7512 - val_sparse_categorical_accuracy: 0.6560\n",
      "Epoch 348/5000\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 4.7015 - sparse_categorical_accuracy: 0.6608 - val_loss: 4.7511 - val_sparse_categorical_accuracy: 0.6566\n",
      "Epoch 349/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7255 - sparse_categorical_accuracy: 0.6665 - val_loss: 4.7693 - val_sparse_categorical_accuracy: 0.6375\n",
      "Epoch 350/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7287 - sparse_categorical_accuracy: 0.6622INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0350.ckpt/assets\n",
      "32/32 [==============================] - 22s 711ms/step - loss: 4.7296 - sparse_categorical_accuracy: 0.6601 - val_loss: 4.7559 - val_sparse_categorical_accuracy: 0.6531\n",
      "Epoch 351/5000\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 4.7112 - sparse_categorical_accuracy: 0.6498 - val_loss: 4.7560 - val_sparse_categorical_accuracy: 0.6411\n",
      "Epoch 352/5000\n",
      "32/32 [==============================] - 14s 448ms/step - loss: 4.7300 - sparse_categorical_accuracy: 0.6610 - val_loss: 4.7640 - val_sparse_categorical_accuracy: 0.6442\n",
      "Epoch 353/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7357 - sparse_categorical_accuracy: 0.6506 - val_loss: 4.7642 - val_sparse_categorical_accuracy: 0.6423\n",
      "Epoch 354/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7011 - sparse_categorical_accuracy: 0.6668 - val_loss: 4.7457 - val_sparse_categorical_accuracy: 0.6572\n",
      "Epoch 355/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7282 - sparse_categorical_accuracy: 0.6621 - val_loss: 4.7558 - val_sparse_categorical_accuracy: 0.6502\n",
      "Epoch 356/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7314 - sparse_categorical_accuracy: 0.6574 - val_loss: 4.7510 - val_sparse_categorical_accuracy: 0.6525\n",
      "Epoch 357/5000\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 4.7080 - sparse_categorical_accuracy: 0.6519 - val_loss: 4.7660 - val_sparse_categorical_accuracy: 0.6332\n",
      "Epoch 358/5000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 4.7257 - sparse_categorical_accuracy: 0.6623 - val_loss: 4.7521 - val_sparse_categorical_accuracy: 0.6507\n",
      "Epoch 359/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7000 - sparse_categorical_accuracy: 0.6680 - val_loss: 4.7692 - val_sparse_categorical_accuracy: 0.6435\n",
      "Epoch 360/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7216 - sparse_categorical_accuracy: 0.6704INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0360.ckpt/assets\n",
      "32/32 [==============================] - 23s 714ms/step - loss: 4.7229 - sparse_categorical_accuracy: 0.6699 - val_loss: 4.7524 - val_sparse_categorical_accuracy: 0.6520\n",
      "Epoch 361/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7315 - sparse_categorical_accuracy: 0.6594 - val_loss: 4.7451 - val_sparse_categorical_accuracy: 0.6554\n",
      "Epoch 362/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7111 - sparse_categorical_accuracy: 0.6569 - val_loss: 4.7468 - val_sparse_categorical_accuracy: 0.6474\n",
      "Epoch 363/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7312 - sparse_categorical_accuracy: 0.6561 - val_loss: 4.7500 - val_sparse_categorical_accuracy: 0.6463\n",
      "Epoch 364/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7367 - sparse_categorical_accuracy: 0.6580 - val_loss: 4.7563 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 365/5000\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7025 - sparse_categorical_accuracy: 0.6562 - val_loss: 4.7743 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 366/5000\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 4.7342 - sparse_categorical_accuracy: 0.6528 - val_loss: 4.7557 - val_sparse_categorical_accuracy: 0.6530\n",
      "Epoch 367/5000\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 4.7300 - sparse_categorical_accuracy: 0.6605 - val_loss: 4.7486 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 368/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7059 - sparse_categorical_accuracy: 0.6570 - val_loss: 4.7444 - val_sparse_categorical_accuracy: 0.6640\n",
      "Epoch 369/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7276 - sparse_categorical_accuracy: 0.6609 - val_loss: 4.7447 - val_sparse_categorical_accuracy: 0.6597\n",
      "Epoch 370/5000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 4.7073 - sparse_categorical_accuracy: 0.6629INFO:tensorflow:Assets written to: experiments/manual_test_double_tnet_05/cp-0370.ckpt/assets\n",
      "32/32 [==============================] - 22s 704ms/step - loss: 4.7091 - sparse_categorical_accuracy: 0.6622 - val_loss: 4.7634 - val_sparse_categorical_accuracy: 0.6505\n",
      "Epoch 371/5000\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 4.7330 - sparse_categorical_accuracy: 0.6598 - val_loss: 4.7550 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 372/5000\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 4.7258 - sparse_categorical_accuracy: 0.6619 - val_loss: 4.7493 - val_sparse_categorical_accuracy: 0.6567\n",
      "Epoch 373/5000\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 4.6951 - sparse_categorical_accuracy: 0.6670 - val_loss: 4.7510 - val_sparse_categorical_accuracy: 0.6524\n",
      "Epoch 374/5000\n",
      "32/32 [==============================] - 14s 444ms/step - loss: 4.7366 - sparse_categorical_accuracy: 0.6520 - val_loss: 4.7569 - val_sparse_categorical_accuracy: 0.6406\n",
      "Epoch 375/5000\n",
      "32/32 [==============================] - 14s 446ms/step - loss: 4.7316 - sparse_categorical_accuracy: 0.6551 - val_loss: 4.7690 - val_sparse_categorical_accuracy: 0.6483\n",
      "Epoch 376/5000\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6955 - sparse_categorical_accuracy: 0.6657"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb Cella 8\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Use CPU as default due to GPU's memory issues\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/CPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         train_x,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         train_y,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49mlatest_ep,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[ValAccThresh_CB(thresh\u001b[39m=\u001b[39;49m\u001b[39m0.85\u001b[39;49m, experiments_path\u001b[39m=\u001b[39;49mexperiments_path, test_name\u001b[39m=\u001b[39;49mtest_name), cp_callback, history_logger],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1252\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1240\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1241\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1251\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1253\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1254\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1255\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1256\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1257\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1258\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1259\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1260\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1261\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1262\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1263\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1264\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1265\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1537\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1536\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1537\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1538\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1539\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:949\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    947\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    950\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    951\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    952\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_name = \"manual_test_double_tnet_05\"\n",
    "\n",
    "k=16\n",
    "batch_size=32\n",
    "steps_per_epoch=32\n",
    "validation_steps=25\n",
    "lr = 0.0001\n",
    "\n",
    "num_points=200\n",
    "num_dims=3\n",
    "\n",
    "checkpoint_path = experiments_path+test_name+\"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=False,\n",
    "    save_freq=10*steps_per_epoch)\n",
    "\n",
    "inputs = keras.Input(shape=(None, 3))\n",
    "\n",
    "tnet_shape = [[[32, 64], [512], [256,128]], [[128], [512], [256,128]]]\n",
    "conv_gnns = [[[128], [128,32]]]\n",
    "dense_gnn = [64,64]\n",
    "\n",
    "outputs = build_model(inputs,\n",
    "                    num_points, num_dims, k,\n",
    "                    tnet_shape,\n",
    "                    conv_gnns,\n",
    "                    dense_gnn\n",
    "                )\n",
    "\n",
    "model = keras.Model(inputs=[inputs], outputs=outputs, name=test_name+\"net\")\n",
    "\n",
    "\n",
    "opt_pi = tf.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_pi, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Try to load the model. If it does not exist, create it.\n",
    "# latest = tf.train.latest_checkpoint(experiments_path+test_name+\"/\")\n",
    "latest = sorted([ f.path for f in os.scandir(experiments_path+test_name) if f.is_dir() ])[-1] \\\n",
    "    if os.path.isdir(experiments_path+test_name) else None\n",
    "\n",
    "if latest:\n",
    "    # https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "    # model.load(latest)\n",
    "    model = tf.keras.models.load_model(latest)\n",
    "    latest_ep = int(latest.split('/')[-1].split('-')[-1].split('.')[0])\n",
    "    print(\" Model loaded correctly:\", latest, \" - Epoch \", latest_ep)\n",
    "else:\n",
    "    print(\" The model at \", experiments_path+test_name+\"/\", \"could not be loaded properly: \", latest)\n",
    "    model.save(checkpoint_path.format(epoch=0))\n",
    "    latest_ep = 0\n",
    "\n",
    "# This grants no overwriting of the history file\n",
    "filename=experiments_path+test_name+\"/history\"+str(latest_ep)+\".csv\"\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "\n",
    "# Use CPU as default due to GPU's memory issues\n",
    "with tf.device('/CPU:0'):\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        \n",
    "        initial_epoch=latest_ep,\n",
    "        batch_size=batch_size, \n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "\n",
    "        validation_split=0.3,\n",
    "        epochs=5000,\n",
    "        shuffle=True,\n",
    "        callbacks=[ValAccThresh_CB(thresh=0.85, experiments_path=experiments_path, test_name=test_name), cp_callback, history_logger],\n",
    "        use_multiprocessing=False,\n",
    "        workers=8,\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
