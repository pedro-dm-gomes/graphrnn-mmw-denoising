{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph NN for MMWave Sensor filtering\n",
    "The idea is to train a classifier to distinguish between fake points and actual ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 12:09:40.706426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:09:40.706493: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Requirements:\n",
    "     * TF:      2.7.0\n",
    "     * Keras:   2.7.0\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "    DO SPLIT AS PEDRO SUGGESTED\n",
    "\n",
    "'''\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Where datasets are stored\n",
    "run_path = \"data/\"\n",
    "experiments_path = \"experiments/\"\n",
    "\n",
    "def load_datasets(init_path):\n",
    "    '''\n",
    "        Return dataset as list of pointclouds\n",
    "        ---\n",
    "        Parameters:\n",
    "        * init_path: string; path to folder holding folders of datasets\n",
    "                     (expected folder structure: 'init_path/run_X/labelled_mmw_run_X.json')\n",
    "    '''\n",
    "    data = []\n",
    "    for run in sorted(os.listdir(init_path)):\n",
    "        if \"run_\" in run:\n",
    "            data.extend(json.load(open(init_path+run+\"/labelled_mmw_\"+run+\".json\"))['labelled_mmw'])\n",
    "    return data\n",
    "\n",
    "def get_data_and_label(data, points_per_cloud=200):\n",
    "    '''\n",
    "        Return samples for training as np.array, divided as unlabelled data and related labels.\n",
    "        ---\n",
    "        Parameters:\n",
    "        * data: list of point clouds. (Usually loaded with function load_datasets)\n",
    "        * points_per_cloud: number of points to be found in each point cloud. (Default is 200)\n",
    "    '''\n",
    "    d_x, d_y = [], []\n",
    "    for pc in data:\n",
    "        for i in range(0, len(pc), points_per_cloud): \n",
    "            if len(pc[i:i+points_per_cloud]) == points_per_cloud:\n",
    "                t_ = np.array(pc[i:i+points_per_cloud])[:, :3]\n",
    "                d_x.append(t_)\n",
    "                d_y.append(np.array(pc[i:i+points_per_cloud], dtype=np.float32)[:, -1])\n",
    "                # d_y.append(tf.one_hot(np.array(pc[i:i+points_per_cloud], dtype=np.float32)[:, -1], 2)) # One Hotted\n",
    "    d_x, d_y = np.stack(d_x), np.stack(d_y)\n",
    "    return d_x, d_y\n",
    "\n",
    "dataset = load_datasets(run_path)\n",
    "\n",
    "'''\n",
    "\n",
    "    DO SPLIT AS PEDRO SUGGESTED\n",
    "\n",
    "'''\n",
    "\n",
    "# Separate Train and Test data\n",
    "d_len = int(len(dataset)*0.7)\n",
    "train, test = dataset[:d_len], dataset[d_len:]\n",
    "# Shuffle point cloud dataset\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)\n",
    "\n",
    "# Get X and Y data for training\n",
    "train_x, train_y = get_data_and_label(train)\n",
    "test_x, test_y = get_data_and_label(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Graph CNN \n",
    "#### https://github.com/WangYueFt/dgcnn\n",
    "#### https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_conv2d(inputs,\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            stride=[1, 1],\n",
    "            padding='SAME',\n",
    "            use_xavier=True,\n",
    "            stddev=1e-3,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            bn=False):\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        strides=stride, \n",
    "        padding=padding,\n",
    "        activation=activation_fn,\n",
    "        kernel_initializer='glorot_uniform' if use_xavier else keras.initializers.TruncatedNormal(stddev=stddev),\n",
    "        bias_initializer='zeros'\n",
    "    )(inputs)\n",
    "\n",
    "    if bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    return x\n",
    "\n",
    "def gnn_dense(inputs,\n",
    "            units,\n",
    "            use_xavier=True,\n",
    "            stddev=1e-3,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            bn=False):\n",
    "            \n",
    "    x = layers.Dense(units,\n",
    "        activation=activation_fn,\n",
    "        kernel_initializer='glorot_uniform' if use_xavier else keras.initializers.TruncatedNormal(stddev=stddev),\n",
    "        bias_initializer='zeros'\n",
    "    )(inputs)\n",
    "\n",
    "    if bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    return x\n",
    "\n",
    "def lambda_get_adj_matr(input):\n",
    "    pcT = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1]))(input)\n",
    "    pc_inn = layers.Lambda(lambda x: tf.matmul(x[0], x[1]))( (input, pcT) )\n",
    "    pc2 = layers.Lambda(lambda x: tf.reduce_sum(tf.square(x), axis=-1, keepdims=True))(input)\n",
    "    pc2T = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1]))(pc2)\n",
    "    output = layers.Lambda(lambda x: x[0] + -2 * x[1] + x[2])( (pc2, pc_inn, pc2T) )\n",
    "    # Uncomment line below to use reciprocal of adj matrix (1/distance)\n",
    "    # output = layers.Lambda(lambda x: tf.math.reciprocal(x))(output)\n",
    "    return output\n",
    "\n",
    "def lambda_knn(adj, k=20):\n",
    "    x = layers.Lambda(lambda x: tf.math.top_k(-x[0], x[1]))( (adj, k) )\n",
    "    return x.indices\n",
    "\n",
    "def lambda_edge_feature(inputs, nn_idxs, k=20, num_points=200, num_dims=3):\n",
    "\n",
    "    pc_central = inputs\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "    idx_ = layers.Lambda(lambda x: tf.range(x[0]) * x[1])( (batch_size, num_points) )\n",
    "    idx_ = layers.Lambda(lambda x: tf.reshape(x[0], (x[1], 1, 1)))( (idx_, batch_size) )\n",
    "    # Adding to list of idxs of k points the points themselves\n",
    "    pc_temp1 = layers.Lambda(lambda x: x[0]+x[1])( (nn_idxs, idx_) )\n",
    "\n",
    "    # Flattening of points into a list of coordinates (x,y,z)\n",
    "    pc_flat = layers.Lambda(lambda x: tf.reshape(x[0], [-1, x[1]]))( (inputs, num_dims) )\n",
    "\n",
    "    # Collect points from computed idxs\n",
    "    pc_neighbors = layers.Lambda(lambda x: tf.gather(x[0], x[1]) )( (pc_flat, pc_temp1) )\n",
    "\n",
    "    # Reshape points into shape (batch, num_points, NEW_AXIS = 1, num_dims)\n",
    "    pc_central = layers.Lambda(lambda x: tf.expand_dims(x, axis=-2))(pc_central)\n",
    "    # Points are repeated k-times along new dimension ==> (batch, num_points, k, num_dims)\n",
    "    pc_central = layers.Lambda(lambda x: tf.tile(x[0], [1, 1, x[1], 1]))( (pc_central, k) )\n",
    "\n",
    "    pc_temp2 = layers.Lambda(lambda x: tf.subtract(x[0], x[1]))( (pc_neighbors, pc_central) )\n",
    "    edge_feature = layers.Lambda(lambda x: tf.concat((x[0], x[1]), axis=-1))((pc_central, pc_temp2))\n",
    "    return edge_feature\n",
    "\n",
    "def gnn_tnet(inputs, num_dims, tnet_shapes, bn=False):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    for filt in tnet_shapes[0]:\n",
    "        x = gnn_conv2d(inputs, filters=filt, kernel_size=[1,1], bn=bn)\n",
    "    x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "    for filt in tnet_shapes[1]:\n",
    "        x = gnn_conv2d(inputs, filters=filt, kernel_size=[1,1], bn=bn)\n",
    "    x = layers.GlobalMaxPooling2D(keepdims=True)(x)\n",
    "    x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], y[2])))( [x, batch_size, x.shape[-1]] )\n",
    "\n",
    "    for neur in tnet_shapes[2]:\n",
    "        x = gnn_dense(x, neur, bn)\n",
    "    \n",
    "    bias = keras.initializers.Constant(np.eye(num_dims).flatten())\n",
    "    x = layers.Dense(\n",
    "        num_dims * num_dims,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_dims, num_dims))(x)\n",
    "    return feat_T\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "# test_name = \"test_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test custom losses\n",
    "def custom_loss(pred, labels):\n",
    "    # loss = tf.compat.v1.losses.softmax_cross_entropy(onehot_labels=labels, logits=pred, label_smoothing=0.2)\n",
    "    # classify_loss = tf.reduce_mean(loss)\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.math.square(tf.math.subtract(labels, pred)), axis=-1))\n",
    "    return loss\n",
    "\n",
    "# Callback to save good models. Threshold is on validation accuracy.\n",
    "class ValAccThresh_CB(keras.callbacks.Callback):\n",
    "    def __init__(self, thresh=0.85, experiments_path=\"experiments/\", test_name=\"test\"):\n",
    "        self.thresh = thresh\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "        self.current_epoch = 0\n",
    "        self.experiments_path = experiments_path\n",
    "        self.test_name = test_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.current_epoch += 1\n",
    "        val_key = \"\"\n",
    "        for k in logs.keys():\n",
    "            if \"val\" in k and \"accuracy\" in k:\n",
    "                val_key = k\n",
    "                break\n",
    "        if val_key == \"\": print(\" Validation Accuracy key not found.\")\n",
    "\n",
    "        current = logs.get(val_key)\n",
    "        # current = logs.get(\"val_accuracy\")\n",
    "        if current >= self.thresh:\n",
    "            self.thresh = current\n",
    "            self.model.save_weights(self.experiments_path+self.test_name+\"/best_weights/cp-\"+str(epoch)+\".ckpt\")\n",
    "            print(\" New good model saved.\")\n",
    "\n",
    "# Callback to save history for post-processing\n",
    "# filename=experiments_path+test_name+\"/history.csv\"\n",
    "# history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, \n",
    "        num_points, num_dims, k,\n",
    "        tnet_shape,\n",
    "        conv_gnns,\n",
    "        dense_gnn,\n",
    "        classes=2):\n",
    "    '''\n",
    "        Returns the outputs of the model to be compiled.\n",
    "        ---\n",
    "        Arguments: \n",
    "        * inputs:       Expected (None, 3). instance of tf.Input.\n",
    "        * num_points:   Number of points per point cloud. Default is 200\n",
    "        * num_dims:     Number of dimensions per point. Default is 3 (x, y, z)\n",
    "        * k:            K nearest neighbors\n",
    "        * tnet_shape:   Array of three lists. (each list's length is the number of layers for that section)\n",
    "                        1st is a list of filters for convolutional layers before reduce_max.\n",
    "                        2nd is a list of filters for convolutional layers after reduce_max.\n",
    "                        3rd is a list of neurons for dense layers after max pooling.\n",
    "        * conv_gnns:    list. Each row is composed of two lists.\n",
    "                        1st is a list of filters for convolutional layers before computing edge features.\n",
    "                        2nd is a list of filters for convolutional layers after computing edge features.\n",
    "        * dense_gnn:    list of neuorns for dense layers at the end of the network.\n",
    "        * classes:      number of classes to classify.\n",
    "    '''\n",
    "\n",
    "    adj = lambda_get_adj_matr(inputs)\n",
    "    nn_idxs = lambda_knn(adj, k)\n",
    "    edge_feats = lambda_edge_feature(inputs, nn_idxs, k, num_points, num_dims)\n",
    "    feat_T = gnn_tnet(edge_feats, num_dims, tnet_shape, bn=True)\n",
    "    pc_tf = layers.Dot(axes=(-1, -2))([inputs, feat_T]) # Apply affine transformation to input features\n",
    "\n",
    "    adj = lambda_get_adj_matr(pc_tf)\n",
    "    nn_idxs = lambda_knn(adj, k)\n",
    "    edge_feats = lambda_edge_feature(pc_tf, nn_idxs, k, num_points, num_dims)\n",
    "\n",
    "    for l in conv_gnns:\n",
    "        x = edge_feats\n",
    "        for gc_filt in l[0]:\n",
    "            x = gnn_conv2d(x, gc_filt, [1,1], bn=True)\n",
    "        x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "        x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], num_points, l[0][-1])))( [x, tf.shape(inputs)[0]] )\n",
    "\n",
    "        adj = lambda_get_adj_matr(x)\n",
    "        nn_idxs = lambda_knn(adj, k)\n",
    "        edge_feats = lambda_edge_feature(x, nn_idxs, k, num_points, l[0][-1])\n",
    "        x = edge_feats\n",
    "        for gc_filt in l[1]:\n",
    "            x = gnn_conv2d(x, gc_filt, [1,1], bn=True)\n",
    "        x = tf.reduce_max(x, axis=-2, keepdims=True)\n",
    "        x = layers.Lambda(lambda y: tf.reshape(y[0], (y[1], num_points, l[1][-1])))( [x, tf.shape(inputs)[0]] )\n",
    "\n",
    "    for w_ in dense_gnn:\n",
    "        x = gnn_dense(x, w_, bn=True)\n",
    "\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    return outputs\n",
    "\n",
    "def objective(trial):\n",
    "    test_name = \"test_\"+str(trial.number)\n",
    "    filename=experiments_path+test_name+\"/history.csv\"\n",
    "    history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "    ############################ HyperParameter Setup ############################\n",
    "    ######################### Check build_model for docs #########################\n",
    "    k = trial.suggest_int('k', 5,75) #30\n",
    "    batch_size = trial.suggest_int('batch_size', 8,128) #16\n",
    "    tnet_before_max = trial.suggest_int('tnet_before_max', 1,3)\n",
    "    tnet_before = []\n",
    "    for i in range(tnet_before_max):\n",
    "        tnet_before.append(trial.suggest_int('tnet_beforemax_layer_'+str(i), 8,128))\n",
    "    tnet_after = []\n",
    "    tnet_after_max = trial.suggest_int('tnet_after_max', 1,3)\n",
    "    for i in range(tnet_after_max):\n",
    "        tnet_after.append(trial.suggest_int('tnet_aftermax_layer_'+str(i), 8,128))\n",
    "    tnet_dense = []\n",
    "    tnet_dense_layers = trial.suggest_int('tnet_dense_layers', 1,3)\n",
    "    for i in range(tnet_dense_layers):\n",
    "        tnet_dense.append(trial.suggest_int('tnet_dense_layer_'+str(i), 16,256))\n",
    "    tnet_shape = [tnet_before, tnet_after, tnet_dense]\n",
    "\n",
    "    gc_layers = trial.suggest_int('gc_layers', 1,3) #1\n",
    "    conv_gnns = []\n",
    "    for _ in range(gc_layers):\n",
    "        before_edge_gcl = trial.suggest_int('before_edge_gcl', 1,3) #2\n",
    "        after_edge_gcl = trial.suggest_int('after_edge_gcl', 1,3) #2\n",
    "\n",
    "        bfr_edge = []\n",
    "        for i in range(before_edge_gcl):\n",
    "            bfr_edge.append(trial.suggest_int('before_edge_gcl_'+str(i), 8,128))\n",
    "            \n",
    "        aft_edge = []\n",
    "        for i in range(after_edge_gcl):\n",
    "            aft_edge.append(trial.suggest_int('after_edge_gcl_'+str(i), 8,128))\n",
    "            \n",
    "        conv_gnns.append([bfr_edge, aft_edge])\n",
    "    dense_layers = trial.suggest_int('dense_layers', 1,3)\n",
    "    dense_gnn = []\n",
    "    for i in range(dense_layers):\n",
    "        dense_gnn.append(trial.suggest_int('dense_layer_'+str(i), 16,256))\n",
    "        \n",
    "    lr = trial.suggest_float('lr', 0.0001, 0.1)\n",
    "    steps_per_epoch=trial.suggest_int('steps_per_epoch', 15,100)\n",
    "\n",
    "    validation_steps=25     # Static\n",
    "    num_points = 200        # Static\n",
    "    num_dims = 3            # Static\n",
    "    ##############################################################################\n",
    "\n",
    "    inputs = keras.Input(shape=(None, num_dims))\n",
    "    \n",
    "    outputs = build_model(inputs,\n",
    "                    num_points, num_dims, k,\n",
    "                    tnet_shape,\n",
    "                    conv_gnns,\n",
    "                    dense_gnn\n",
    "                )\n",
    "    model = keras.Model(inputs=[inputs], outputs=outputs, name=\"gnn_pointnet\")\n",
    "\n",
    "    opt_pi = tf.optimizers.Adam(learning_rate =  lr )\n",
    "    # opt_pi = tf.optimizers.RMSprop(learning_rate =  lr )\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_pi, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    # model.compile(loss=tf.nn.sparse_softmax_cross_entropy_with_logits , optimizer=opt_pi, metrics=['accuracy'])\n",
    "    # model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=opt_pi, metrics=['accuracy'])\n",
    "    # model.compile(loss=custom_loss, optimizer=opt_pi, metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_path = experiments_path+test_name+\"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=0, \n",
    "        save_weights_only=False,\n",
    "        save_freq=10*batch_size)\n",
    "        \n",
    "    latest = tf.train.latest_checkpoint(experiments_path+test_name+\"/\")\n",
    "    if latest:\n",
    "        model.load_weights(latest)\n",
    "        latest_ep = int(latest.split('/')[-1].split('-')[-1].split('.')[0])\n",
    "        print(\" Model loaded correctly:\", latest, \" - Epoch \", latest_ep)\n",
    "    else:\n",
    "        print(\" The model could not be loaded properly: \", latest)\n",
    "        model.save_weights(checkpoint_path.format(epoch=0))\n",
    "        latest_ep = 0\n",
    "\n",
    "    # Use CPU as default due to GPU's memory issues\n",
    "    with tf.device('/CPU:0'):\n",
    "        history = model.fit(\n",
    "            train_x, \n",
    "            train_y, \n",
    "            \n",
    "            initial_epoch=latest_ep,\n",
    "            batch_size=batch_size, \n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "\n",
    "            validation_split=0.3,\n",
    "            epochs=150 - latest_ep, # Train for 150 epochs to find the configuration that can later be trained for more epochs.\n",
    "            shuffle=True,\n",
    "            callbacks=[ValAccThresh_CB(thresh=0.85, experiments_path=experiments_path, test_name=test_name),\n",
    "                        cp_callback,\n",
    "                        history_logger],\n",
    "            use_multiprocessing=False,\n",
    "            workers=8,\n",
    "        )\n",
    "    return np.mean(history.history['val_sparse_categorical_accuracy'][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-15 10:37:27,190]\u001b[0m A new study created in RDB with name: gnn_denoising\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The model could not be loaded properly:  None\n",
      "Epoch 1/150\n",
      "11/97 [==>...........................] - ETA: 10:20 - loss: 0.8385 - sparse_categorical_accuracy: 0.5473"
     ]
    }
   ],
   "source": [
    "# Actually train\n",
    "storage = optuna.storages.RDBStorage(url=\"sqlite:///gnn.db\", engine_kwargs={\"connect_args\": {\"timeout\": 5}})\n",
    "study = optuna.create_study(study_name=\"gnn_denoising\", storage=storage, load_if_exists=True, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Configurations Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 12:11:47.084408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 12:11:47.085330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.085547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.085721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.085917: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.086171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.086419: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.086659: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.086916: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib::/home/walter/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2023-01-26 12:11:47.086948: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-26 12:11:47.087427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded correctly: experiments/manual_test_0/cp-0000.ckpt  - Epoch  0\n",
      "Epoch 1/20000\n",
      "33/33 [==============================] - 137s 4s/step - loss: 0.9204 - sparse_categorical_accuracy: 0.6007 - val_loss: 4.8578 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 2/20000\n",
      "33/33 [==============================] - 136s 4s/step - loss: 0.7410 - sparse_categorical_accuracy: 0.5908 - val_loss: 5.3035 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 3/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6860 - sparse_categorical_accuracy: 0.6463 - val_loss: 3.7385 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 4/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6757 - sparse_categorical_accuracy: 0.6384 - val_loss: 0.9808 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 5/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.7143 - sparse_categorical_accuracy: 0.6338 - val_loss: 1.2035 - val_sparse_categorical_accuracy: 0.3330\n",
      "Epoch 6/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6889 - sparse_categorical_accuracy: 0.6464 - val_loss: 1.0364 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 7/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.7110 - sparse_categorical_accuracy: 0.6310 - val_loss: 1.0118 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 8/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.7050 - sparse_categorical_accuracy: 0.6337 - val_loss: 0.7574 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 9/20000\n",
      "33/33 [==============================] - 124s 4s/step - loss: 0.6844 - sparse_categorical_accuracy: 0.6420 - val_loss: 1.4159 - val_sparse_categorical_accuracy: 0.6598\n",
      "Epoch 10/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6950 - sparse_categorical_accuracy: 0.6489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 12:32:56.230199: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0010.ckpt/assets\n",
      "33/33 [==============================] - 141s 4s/step - loss: 0.6947 - sparse_categorical_accuracy: 0.6488 - val_loss: 1.1085 - val_sparse_categorical_accuracy: 0.6670\n",
      "Epoch 11/20000\n",
      "33/33 [==============================] - 130s 4s/step - loss: 0.6707 - sparse_categorical_accuracy: 0.6380 - val_loss: 2.3658 - val_sparse_categorical_accuracy: 0.6192\n",
      "Epoch 12/20000\n",
      "33/33 [==============================] - 130s 4s/step - loss: 0.6755 - sparse_categorical_accuracy: 0.6472 - val_loss: 4.5955 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 13/20000\n",
      "33/33 [==============================] - 129s 4s/step - loss: 0.6793 - sparse_categorical_accuracy: 0.6395 - val_loss: 50.8451 - val_sparse_categorical_accuracy: 0.4027\n",
      "Epoch 14/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.7187 - sparse_categorical_accuracy: 0.5986 - val_loss: 175.7962 - val_sparse_categorical_accuracy: 0.3523\n",
      "Epoch 15/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.7187 - sparse_categorical_accuracy: 0.5924 - val_loss: 220.8722 - val_sparse_categorical_accuracy: 0.3987\n",
      "Epoch 16/20000\n",
      "33/33 [==============================] - 131s 4s/step - loss: 0.6867 - sparse_categorical_accuracy: 0.6831 - val_loss: 107.3983 - val_sparse_categorical_accuracy: 0.4212\n",
      "Epoch 17/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6871 - sparse_categorical_accuracy: 0.5991 - val_loss: 135.0084 - val_sparse_categorical_accuracy: 0.6480\n",
      "Epoch 18/20000\n",
      "33/33 [==============================] - 129s 4s/step - loss: 0.6788 - sparse_categorical_accuracy: 0.6723 - val_loss: 243.7990 - val_sparse_categorical_accuracy: 0.6846\n",
      "Epoch 19/20000\n",
      "33/33 [==============================] - 132s 4s/step - loss: 0.6706 - sparse_categorical_accuracy: 0.6218 - val_loss: 87.7819 - val_sparse_categorical_accuracy: 0.3320\n",
      "Epoch 20/20000\n",
      "32/33 [============================>.] - ETA: 5s - loss: 0.6903 - sparse_categorical_accuracy: 0.6651 INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0020.ckpt/assets\n",
      "33/33 [==============================] - 226s 7s/step - loss: 0.6893 - sparse_categorical_accuracy: 0.6649 - val_loss: 26.2322 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 21/20000\n",
      "33/33 [==============================] - 207s 6s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5952 - val_loss: 10.1943 - val_sparse_categorical_accuracy: 0.6641\n",
      "Epoch 22/20000\n",
      "33/33 [==============================] - 200s 6s/step - loss: 0.6930 - sparse_categorical_accuracy: 0.6674 - val_loss: 111.5974 - val_sparse_categorical_accuracy: 0.6877\n",
      "Epoch 23/20000\n",
      "33/33 [==============================] - 200s 6s/step - loss: 0.6698 - sparse_categorical_accuracy: 0.6253 - val_loss: 326.5226 - val_sparse_categorical_accuracy: 0.6561\n",
      "Epoch 24/20000\n",
      "33/33 [==============================] - 205s 6s/step - loss: 0.6887 - sparse_categorical_accuracy: 0.6657 - val_loss: 465.0410 - val_sparse_categorical_accuracy: 0.6387\n",
      "Epoch 25/20000\n",
      "33/33 [==============================] - 203s 6s/step - loss: 0.6867 - sparse_categorical_accuracy: 0.6168 - val_loss: 1207.1816 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 26/20000\n",
      "33/33 [==============================] - 205s 6s/step - loss: 0.6753 - sparse_categorical_accuracy: 0.6403 - val_loss: 721.5657 - val_sparse_categorical_accuracy: 0.6649\n",
      "Epoch 27/20000\n",
      "33/33 [==============================] - 198s 6s/step - loss: 0.6731 - sparse_categorical_accuracy: 0.6511 - val_loss: 501.7686 - val_sparse_categorical_accuracy: 0.5207\n",
      "Epoch 28/20000\n",
      "33/33 [==============================] - 201s 6s/step - loss: 0.6688 - sparse_categorical_accuracy: 0.6358 - val_loss: 376.4904 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 29/20000\n",
      "33/33 [==============================] - 200s 6s/step - loss: 0.6529 - sparse_categorical_accuracy: 0.6784 - val_loss: 449.1421 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 30/20000\n",
      "32/33 [============================>.] - ETA: 5s - loss: 0.6586 - sparse_categorical_accuracy: 0.6450 INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0030.ckpt/assets\n",
      "33/33 [==============================] - 221s 7s/step - loss: 0.6579 - sparse_categorical_accuracy: 0.6464 - val_loss: 190.8988 - val_sparse_categorical_accuracy: 0.6771\n",
      "Epoch 31/20000\n",
      "33/33 [==============================] - 206s 6s/step - loss: 0.6609 - sparse_categorical_accuracy: 0.6771 - val_loss: 1699.6545 - val_sparse_categorical_accuracy: 0.3278\n",
      "Epoch 32/20000\n",
      "33/33 [==============================] - 142s 4s/step - loss: 0.6573 - sparse_categorical_accuracy: 0.6631 - val_loss: 1520.9552 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 33/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6780 - val_loss: 342.6546 - val_sparse_categorical_accuracy: 0.6611\n",
      "Epoch 34/20000\n",
      "33/33 [==============================] - 129s 4s/step - loss: 0.6572 - sparse_categorical_accuracy: 0.6686 - val_loss: 1072.7844 - val_sparse_categorical_accuracy: 0.6899\n",
      "Epoch 35/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6577 - sparse_categorical_accuracy: 0.6697 - val_loss: 1722.0291 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 36/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6483 - sparse_categorical_accuracy: 0.6745 - val_loss: 2772.5662 - val_sparse_categorical_accuracy: 0.3742\n",
      "Epoch 37/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6447 - sparse_categorical_accuracy: 0.6729 - val_loss: 4672.0928 - val_sparse_categorical_accuracy: 0.6207\n",
      "Epoch 38/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6775 - val_loss: 8215.6211 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 39/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6803 - val_loss: 12158.9111 - val_sparse_categorical_accuracy: 0.6813\n",
      "Epoch 40/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6551 - sparse_categorical_accuracy: 0.6514INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0040.ckpt/assets\n",
      "33/33 [==============================] - 139s 4s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6514 - val_loss: 22982.0312 - val_sparse_categorical_accuracy: 0.6084\n",
      "Epoch 41/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6429 - sparse_categorical_accuracy: 0.6787 - val_loss: 120063.8047 - val_sparse_categorical_accuracy: 0.3691\n",
      "Epoch 42/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6546 - sparse_categorical_accuracy: 0.6581 - val_loss: 149526.2656 - val_sparse_categorical_accuracy: 0.5320\n",
      "Epoch 43/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6728 - val_loss: 290079.8750 - val_sparse_categorical_accuracy: 0.4619\n",
      "Epoch 44/20000\n",
      "33/33 [==============================] - 125s 4s/step - loss: 0.6464 - sparse_categorical_accuracy: 0.6798 - val_loss: 156435.7188 - val_sparse_categorical_accuracy: 0.6314\n",
      "Epoch 45/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6703 - val_loss: 152730.4844 - val_sparse_categorical_accuracy: 0.4518\n",
      "Epoch 46/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6763 - val_loss: 822839.0000 - val_sparse_categorical_accuracy: 0.3373\n",
      "Epoch 47/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6370 - sparse_categorical_accuracy: 0.6734 - val_loss: 1075871.6250 - val_sparse_categorical_accuracy: 0.6101\n",
      "Epoch 48/20000\n",
      "33/33 [==============================] - 129s 4s/step - loss: 0.6400 - sparse_categorical_accuracy: 0.6713 - val_loss: 3570233.0000 - val_sparse_categorical_accuracy: 0.3228\n",
      "Epoch 49/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6443 - sparse_categorical_accuracy: 0.6701 - val_loss: 6104018.0000 - val_sparse_categorical_accuracy: 0.3285\n",
      "Epoch 50/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6457 - sparse_categorical_accuracy: 0.6774INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0050.ckpt/assets\n",
      "33/33 [==============================] - 142s 4s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6762 - val_loss: 17149924.0000 - val_sparse_categorical_accuracy: 0.3245\n",
      "Epoch 51/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6371 - sparse_categorical_accuracy: 0.6779 - val_loss: 26837576.0000 - val_sparse_categorical_accuracy: 0.3227\n",
      "Epoch 52/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6393 - sparse_categorical_accuracy: 0.6780 - val_loss: 48313260.0000 - val_sparse_categorical_accuracy: 0.3265\n",
      "Epoch 53/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6430 - sparse_categorical_accuracy: 0.6724 - val_loss: 65939284.0000 - val_sparse_categorical_accuracy: 0.3282\n",
      "Epoch 54/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6405 - sparse_categorical_accuracy: 0.6781 - val_loss: 96920616.0000 - val_sparse_categorical_accuracy: 0.3212\n",
      "Epoch 55/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6778 - val_loss: 129028152.0000 - val_sparse_categorical_accuracy: 0.3190\n",
      "Epoch 56/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6466 - sparse_categorical_accuracy: 0.6794 - val_loss: 154168352.0000 - val_sparse_categorical_accuracy: 0.3164\n",
      "Epoch 57/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6445 - sparse_categorical_accuracy: 0.6746 - val_loss: 149587984.0000 - val_sparse_categorical_accuracy: 0.3299\n",
      "Epoch 58/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6550 - sparse_categorical_accuracy: 0.6494 - val_loss: 128511552.0000 - val_sparse_categorical_accuracy: 0.3206\n",
      "Epoch 59/20000\n",
      "33/33 [==============================] - 131s 4s/step - loss: 0.6406 - sparse_categorical_accuracy: 0.6780 - val_loss: 78816304.0000 - val_sparse_categorical_accuracy: 0.3296\n",
      "Epoch 60/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6401 - sparse_categorical_accuracy: 0.6748INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0060.ckpt/assets\n",
      "33/33 [==============================] - 139s 4s/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6764 - val_loss: 10644224.0000 - val_sparse_categorical_accuracy: 0.5607\n",
      "Epoch 61/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6432 - sparse_categorical_accuracy: 0.6691 - val_loss: 63197532.0000 - val_sparse_categorical_accuracy: 0.6727\n",
      "Epoch 62/20000\n",
      "33/33 [==============================] - 125s 4s/step - loss: 0.6325 - sparse_categorical_accuracy: 0.6809 - val_loss: 14375569.0000 - val_sparse_categorical_accuracy: 0.6269\n",
      "Epoch 63/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6358 - sparse_categorical_accuracy: 0.6768 - val_loss: 8123024.5000 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 64/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6451 - sparse_categorical_accuracy: 0.6712 - val_loss: 3844782.5000 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 65/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6411 - sparse_categorical_accuracy: 0.6696 - val_loss: 5541954.0000 - val_sparse_categorical_accuracy: 0.4489\n",
      "Epoch 66/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6379 - sparse_categorical_accuracy: 0.6813 - val_loss: 14210221.0000 - val_sparse_categorical_accuracy: 0.4066\n",
      "Epoch 67/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6467 - sparse_categorical_accuracy: 0.6717 - val_loss: 13452344.0000 - val_sparse_categorical_accuracy: 0.4307\n",
      "Epoch 68/20000\n",
      "33/33 [==============================] - 129s 4s/step - loss: 0.6352 - sparse_categorical_accuracy: 0.6815 - val_loss: 19657154.0000 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 69/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6372 - sparse_categorical_accuracy: 0.6781 - val_loss: 30449386.0000 - val_sparse_categorical_accuracy: 0.4049\n",
      "Epoch 70/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6396 - sparse_categorical_accuracy: 0.6775INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0070.ckpt/assets\n",
      "33/33 [==============================] - 141s 4s/step - loss: 0.6388 - sparse_categorical_accuracy: 0.6782 - val_loss: 42060708.0000 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 71/20000\n",
      "33/33 [==============================] - 125s 4s/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6810 - val_loss: 58482420.0000 - val_sparse_categorical_accuracy: 0.3820\n",
      "Epoch 72/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6398 - sparse_categorical_accuracy: 0.6736 - val_loss: 15509242.0000 - val_sparse_categorical_accuracy: 0.4336\n",
      "Epoch 73/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6402 - sparse_categorical_accuracy: 0.6743 - val_loss: 15295205.0000 - val_sparse_categorical_accuracy: 0.4600\n",
      "Epoch 74/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6359 - sparse_categorical_accuracy: 0.6790 - val_loss: 1949499.3750 - val_sparse_categorical_accuracy: 0.6541\n",
      "Epoch 75/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6376 - sparse_categorical_accuracy: 0.6757 - val_loss: 2651696.5000 - val_sparse_categorical_accuracy: 0.6654\n",
      "Epoch 76/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6340 - sparse_categorical_accuracy: 0.6741 - val_loss: 275727.7188 - val_sparse_categorical_accuracy: 0.5938\n",
      "Epoch 77/20000\n",
      "33/33 [==============================] - 126s 4s/step - loss: 0.6397 - sparse_categorical_accuracy: 0.6751 - val_loss: 181516.2812 - val_sparse_categorical_accuracy: 0.6718\n",
      "Epoch 78/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6383 - sparse_categorical_accuracy: 0.6769 - val_loss: 228011.5625 - val_sparse_categorical_accuracy: 0.6639\n",
      "Epoch 79/20000\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.6321 - sparse_categorical_accuracy: 0.6808 - val_loss: 411867.8125 - val_sparse_categorical_accuracy: 0.4071\n",
      "Epoch 80/20000\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.6313 - sparse_categorical_accuracy: 0.6822INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0080.ckpt/assets\n",
      "33/33 [==============================] - 142s 4s/step - loss: 0.6306 - sparse_categorical_accuracy: 0.6828 - val_loss: 15067.7998 - val_sparse_categorical_accuracy: 0.5200\n",
      "Epoch 81/20000\n",
      "33/33 [==============================] - 128s 4s/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6760 - val_loss: 161495.9062 - val_sparse_categorical_accuracy: 0.3233\n",
      "Epoch 82/20000\n",
      "33/33 [==============================] - 154s 5s/step - loss: 0.6346 - sparse_categorical_accuracy: 0.6760 - val_loss: 374017.1250 - val_sparse_categorical_accuracy: 0.3211\n",
      "Epoch 83/20000\n",
      "33/33 [==============================] - 222s 7s/step - loss: 0.6387 - sparse_categorical_accuracy: 0.6716 - val_loss: 521321.7500 - val_sparse_categorical_accuracy: 0.3201\n",
      "Epoch 84/20000\n",
      "33/33 [==============================] - 215s 7s/step - loss: 0.6363 - sparse_categorical_accuracy: 0.6748 - val_loss: 864336.3125 - val_sparse_categorical_accuracy: 0.3237\n",
      "Epoch 85/20000\n",
      "33/33 [==============================] - 210s 6s/step - loss: 0.6318 - sparse_categorical_accuracy: 0.6785 - val_loss: 843260.4375 - val_sparse_categorical_accuracy: 0.4369\n",
      "Epoch 86/20000\n",
      "33/33 [==============================] - 207s 6s/step - loss: 0.6355 - sparse_categorical_accuracy: 0.6740 - val_loss: 576305.5625 - val_sparse_categorical_accuracy: 0.4677\n",
      "Epoch 87/20000\n",
      "33/33 [==============================] - 207s 6s/step - loss: 0.6307 - sparse_categorical_accuracy: 0.6823 - val_loss: 702665.5625 - val_sparse_categorical_accuracy: 0.4838\n",
      "Epoch 88/20000\n",
      "33/33 [==============================] - 210s 6s/step - loss: 0.6344 - sparse_categorical_accuracy: 0.6775 - val_loss: 350220.7500 - val_sparse_categorical_accuracy: 0.5064\n",
      "Epoch 89/20000\n",
      "33/33 [==============================] - 205s 6s/step - loss: 0.6319 - sparse_categorical_accuracy: 0.6804 - val_loss: 153281.9062 - val_sparse_categorical_accuracy: 0.5251\n",
      "Epoch 90/20000\n",
      "32/33 [============================>.] - ETA: 5s - loss: 0.6382 - sparse_categorical_accuracy: 0.6656 INFO:tensorflow:Assets written to: experiments/manual_test_0/cp-0090.ckpt/assets\n",
      "33/33 [==============================] - 217s 7s/step - loss: 0.6390 - sparse_categorical_accuracy: 0.6646 - val_loss: 91818.6562 - val_sparse_categorical_accuracy: 0.6811\n",
      "Epoch 91/20000\n",
      "23/33 [===================>..........] - ETA: 51s - loss: 0.6313 - sparse_categorical_accuracy: 0.6776"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb Cella 9\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Use CPU as default due to GPU's memory issues\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/CPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         train_x, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         train_y, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49mlatest_ep,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m20000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[ValAccThresh_CB(thresh\u001b[39m=\u001b[39;49m\u001b[39m0.85\u001b[39;49m, experiments_path\u001b[39m=\u001b[39;49mexperiments_path, test_name\u001b[39m=\u001b[39;49mtest_name), cp_callback, history_logger],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/walter/graphrnn-mmw-denoising/gnn_tf.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_name = \"manual_test_01\"\n",
    "\n",
    "k=27\n",
    "batch_size=66\n",
    "steps_per_epoch=33\n",
    "validation_steps=25\n",
    "lr = 0.06283\n",
    "\n",
    "num_points=200\n",
    "num_dims=3\n",
    "\n",
    "checkpoint_path = experiments_path+test_name+\"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=False,\n",
    "    save_freq=10*steps_per_epoch)\n",
    "\n",
    "inputs = keras.Input(shape=(None, 3))\n",
    "\n",
    "tnet_shape = [[32], [128], [128,128]]\n",
    "conv_gnns = [[[32,64], [128]]]\n",
    "dense_gnn = [256,128]\n",
    "\n",
    "outputs = build_model(inputs,\n",
    "                    num_points, num_dims, k,\n",
    "                    tnet_shape,\n",
    "                    conv_gnns,\n",
    "                    dense_gnn\n",
    "                )\n",
    "\n",
    "model = keras.Model(inputs=[inputs], outputs=outputs, name=test_name+\"net\")\n",
    "\n",
    "\n",
    "opt_pi = tf.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_pi, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Try to load the model. If it does not exist, create it.\n",
    "latest = tf.train.latest_checkpoint(experiments_path+test_name+\"/\")\n",
    "if latest:\n",
    "    model.load_weights(latest)\n",
    "    latest_ep = int(latest.split('/')[-1].split('-')[-1].split('.')[0])\n",
    "    print(\" Model loaded correctly:\", latest, \" - Epoch \", latest_ep)\n",
    "else:\n",
    "    print(\" The model could not be loaded properly: \", latest)\n",
    "    model.save_weights(checkpoint_path.format(epoch=0))\n",
    "    latest_ep = 0\n",
    "\n",
    "# This grants no overwriting of the history file\n",
    "filename=experiments_path+test_name+\"/history\"+str(latest_ep)+\".csv\"\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
    "\n",
    "# Use CPU as default due to GPU's memory issues\n",
    "with tf.device('/CPU:0'):\n",
    "    history = model.fit(\n",
    "        train_x, \n",
    "        train_y, \n",
    "        \n",
    "        initial_epoch=latest_ep,\n",
    "        batch_size=batch_size, \n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "\n",
    "        validation_split=0.3,\n",
    "        epochs=20000,\n",
    "        shuffle=True,\n",
    "        callbacks=[ValAccThresh_CB(thresh=0.85, experiments_path=experiments_path, test_name=test_name), cp_callback, history_logger],\n",
    "        use_multiprocessing=False,\n",
    "        workers=8,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
